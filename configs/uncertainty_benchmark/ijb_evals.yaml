hydra:
  run:
    dir: ${exp_dir}

#exp_dir: experiments/open_set_uncertainty_small_beta
exp_dir: outputs/experiments/open_set_uncertainty
use_two_galleries: True
recompute_template_pooling: False

# test_dataset:
#   _target_: evaluation.test_datasets.FaceRecogntioniDataset
#   dataset_name: survFace
#   dataset_path: /app/datasets/QMUL-SurvFace/Face_Identification_Test_Set

test_dataset:
  _target_: evaluation.test_datasets.FaceRecogntioniDataset
  dataset_name: IJBC
  dataset_path: /app/datasets/arcface_ijb/IJBC



open_set_identification_metrics:
  - _target_: evaluation.metrics.DetectionAndIdentificationRate
    top_n_ranks: [1, 5, 10, 20]
    far_range: [-4, 0, 100]
    display_fars: [0.0001, 0.001, 0.01, 0.1, 1]

closed_set_identification_metrics:
  - _target_: evaluation.metrics.CMC
    top_n_ranks: [1, 2, 3, 5, 10, 20, 50, 100, 500, 1000]
    display_ranks: [1, 5, 10, 50, 100, 500, 1000]

verification_metrics:
  - _target_: evaluation.metrics.TarFar
    far_range: [-6, 0, 100]
    display_fars: [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1]

fractions: [0, 0.55, 0.05]

# metric_to_monitor:
#   _target_: evaluation.metrics.DetectionAndIdentificationRate
#   top_n_ranks: [1, 20] #[1, 10, 20]
#   far_range: [-4, 0, 100] 
#   display_fars: [0.0001, 0.001, 0.01, 0.1, 1]

metric_to_monitor:
  _target_: evaluation.metrics.DetectionAndIdentificationRate
  top_n_ranks: [1, 20] #[1, 10, 20]
  far_range: [-4, 0, 100] 
  display_fars: [0.0001, 0.001, 0.01, 0.1, 1]

open_set_uncertainty_metrics:
  - _target_: evaluation.uncertainty_metrics.BernoulliVarianceReject
    fractions: ${fractions}
    metric_to_monitor: ${metric_to_monitor}

  # - _target_: evaluation.uncertainty_metrics.CombinedMaxProb
  #   fractions: ${fractions}
  #   kappa: 200
  #   beta: 0.5
  #   use_maxprob_variance: False
  #   data_variance_weight: 0
  #   metric_to_monitor: ${metric_to_monitor}


  # - _target_: evaluation.uncertainty_metrics.CombinedMaxProb
  #   fractions: ${fractions}
  #   kappa: 200
  #   beta: 0.001
  #   use_maxprob_variance: False
  #   data_variance_weight: 0
  #   metric_to_monitor: ${metric_to_monitor}

  # - _target_: evaluation.uncertainty_metrics.CombinedMaxProb
  #   fractions: ${fractions}
  #   kappa: 400
  #   beta: 0.01
  #   use_maxprob_variance: False
  #   aggregation: maxprob
  #   data_variance_weight: 0
  #   metric_to_monitor: ${metric_to_monitor}

  - _target_: evaluation.uncertainty_metrics.CombinedMaxProb
    fractions: ${fractions}
    kappa: 400
    beta: 0.5
    use_maxprob_variance: False
    aggregation: entr
    data_variance_weight: 0
    metric_to_monitor: ${metric_to_monitor}
      
  # - _target_: evaluation.uncertainty_metrics.CombinedMaxProb
  #   fractions: ${fractions}
  #   kappa: 400
  #   beta: 0.5
  #   use_maxprob_variance: False
  #   aggregation: maxprob
  #   data_variance_weight: 0.7
  #   metric_to_monitor: ${metric_to_monitor}

  - _target_: evaluation.uncertainty_metrics.CombinedMaxProb
    fractions: ${fractions}
    kappa: 400
    beta: 0.5
    use_maxprob_variance: False
    aggregation: entr
    data_variance_weight: 0.7
    metric_to_monitor: ${metric_to_monitor}

  - _target_: evaluation.uncertainty_metrics.CombinedMaxProb
    fractions: ${fractions}
    kappa: 200
    beta: 0.5
    aggregation: entr
    use_maxprob_variance: False
    data_variance_weight: 1
    metric_to_monitor: ${metric_to_monitor}

  # - _target_: evaluation.uncertainty_metrics.CombinedMaxProb
  #   fractions: ${fractions}
  #   sample: False
  #   kappa: 200
  #   beta: 0.05
  #   use_entropy: True
  #   metric_to_monitor:
  #     _target_: evaluation.metrics.DetectionAndIdentificationRate
  #     top_n_ranks: [1, 20] #[1, 10, 20]
  #     far_range: [-4, 0, 100] 
  #     display_fars: [0.0001, 0.001, 0.01, 0.1, 1]

  # - _target_: evaluation.uncertainty_metrics.MeanDistanceReject
  #   fractions: ${fractions}
  #   sample: False
  #   metric_to_monitor:
  #     _target_: evaluation.metrics.DetectionAndIdentificationRate
  #     top_n_ranks: [1, 20]
  #     far_range: [-4, 0, 100] 
  #     display_fars: [0.0001, 0.001, 0.01, 0.1, 1]


open_set_identification_methods:
  # - evaluation_function: 
  #     _target_: evaluation.eval_functions.open_set_identification.SCF
  #     k_shift: 0
  #     cosine_pred: False
  #     confidence_function: 
  #       _target_: evaluation.confidence_functions.MaxSimilarity_confidence
  #   embeddings_path: ${test_dataset.dataset_path}/embeddings/scf_embs_${test_dataset.dataset_name}.npz
  #   template_pooling_strategy:
  #     _target_: evaluation.template_pooling_strategies.PoolingSCF
  #   use_detector_score: True
  #   pretty_name: $s(p) =  \max_{c\in\{1,\dots,K\}}sim_{scf}(mu_{c}, z)$
  # - sampler:
  #     _target_: evaluation.samplers.VonMisesFisher
  #     num_samples: 10 # set 0 to use mean of distr as one sample
  #   evaluation_function: 
  #     _target_: evaluation.eval_functions.open_set_identification.CosineSim
  #     confidence_function: 
  #       _target_: evaluation.confidence_functions.MaxSimilarity_confidence
  #   embeddings_path: ${test_dataset.dataset_path}/embeddings/scf_embs_${test_dataset.dataset_name}.npz
  #   template_pooling_strategy:
  #     _target_: evaluation.template_pooling_strategies.PoolingSCF
  #   use_detector_score: True
  #   pretty_name: $s(p) =  \max_{c\in\{1,\dots,K\}}\mu^T_{c}z$, 10 samples

  # - sampler:
  #     _target_: evaluation.samplers.VonMisesFisher
  #     num_samples: 0 # set 0 to use mean of distr as one sample
  #   evaluation_function: 
  #     _target_: evaluation.eval_functions.open_set_identification.CosineSim
  #     confidence_function: 
  #       _target_: evaluation.confidence_functions.MaxSimilarity_confidence
  #   embeddings_path: ${test_dataset.dataset_path}/embeddings/scf_embs_${test_dataset.dataset_name}.npz
  #   template_pooling_strategy:
  #     _target_: evaluation.template_pooling_strategies.PoolingDefault
  #   use_detector_score: True
  #   pretty_name: NoSCF

  - sampler:
      _target_: evaluation.samplers.VonMisesFisher
      num_samples: 0 # set 0 to use mean of distr as one sample
    evaluation_function: 
      _target_: evaluation.eval_functions.open_set_identification.CosineSim
      confidence_function: 
        _target_: evaluation.confidence_functions.MaxSimilarity_confidence
    embeddings_path: ${test_dataset.dataset_path}/embeddings/scf_embs_${test_dataset.dataset_name}.npz
    template_pooling_strategy:
      _target_: evaluation.template_pooling_strategies.PoolingSCF
    use_detector_score: True
    pretty_name: "Cosine"
  
  # - evaluation_function: 
  #     _target_: evaluation.eval_functions.open_set_identification.CosineSim
  #     confidence_function: 
  #       _target_: evaluation.confidence_functions.NAC_confidence
  #       k: 120
  #       s: 1
  #       normalize: True
  #     k_shift: 0
  #     cosine_pred: False
  #   embeddings_path: ${test_dataset.dataset_path}/embeddings/scf_embs_${test_dataset.dataset_name}.npz
  #   template_pooling_strategy:
  #     _target_: evaluation.template_pooling_strategies.PoolingSCF
  #   use_detector_score: True
  #   pretty_name: SCF_NAC-k=120

  # - sampler:
  #     _target_: evaluation.samplers.VonMisesFisher
  #     num_samples: 0 # set 0 to use mean of distr as one sample
  #   evaluation_function:
  #     _target_: evaluation.eval_functions.open_set_identification.CosineSim
  #     confidence_function: 
  #       _target_: evaluation.confidence_functions.MisesProb
  #       kappa: 200
  #       beta: 0.5
  #   embeddings_path: ${test_dataset.dataset_path}/embeddings/scf_embs_${test_dataset.dataset_name}.npz
  #   template_pooling_strategy:
  #     _target_: evaluation.template_pooling_strategies.PoolingSCF
  #   use_detector_score: True
  #   pretty_name: "CosineSim Conf kappa=200"
