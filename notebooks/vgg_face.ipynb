{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "from onnx2torch import convert\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnx2torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kolesnikov/miniconda/lib/python3.9/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### load ds\n",
    "from face_lib.dataset_classes.lightning_datasets import MXFaceDataset\n",
    "\n",
    "vgg_ds = MXFaceDataset(\"/app/datasets/faces_vgg_112x112\")\n",
    "# softmax_weights_path = '/app/model_weights/softmax_weight.pt'\n",
    "# softmax_weights = torch.load(softmax_weights_path)\n",
    "# softmax_weights_norm = torch.norm(\n",
    "#             softmax_weights, dim=1, keepdim=True\n",
    "#         )  # [N, 512]\n",
    "# softmax_weights = (\n",
    "#             softmax_weights / softmax_weights_norm\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"/app/model_weights/backbone/vgg_iresnet50/vgg2_r50.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = convert(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"/app/datasets/faces_vgg_112x112/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tuple = np.unique(labels, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259\n"
     ]
    }
   ],
   "source": [
    "print(labels_tuple[1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (Conv_0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (initializers): Module()\n",
       "  (PRelu_1): OnnxPReLU()\n",
       "  (BatchNormalization_2): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_4): OnnxPReLU()\n",
       "  (Conv_5): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (Conv_6): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_7): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_8): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_10): OnnxPReLU()\n",
       "  (Conv_11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_12): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_13): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_15): OnnxPReLU()\n",
       "  (Conv_16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_17): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_18): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_19): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_20): OnnxPReLU()\n",
       "  (Conv_21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (Conv_22): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_23): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_24): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_25): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_26): OnnxPReLU()\n",
       "  (Conv_27): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_28): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_29): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_30): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_31): OnnxPReLU()\n",
       "  (Conv_32): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_33): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_34): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_35): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_36): OnnxPReLU()\n",
       "  (Conv_37): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_38): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_39): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_40): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_41): OnnxPReLU()\n",
       "  (Conv_42): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (Conv_43): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_44): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_45): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_46): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_47): OnnxPReLU()\n",
       "  (Conv_48): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_49): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_50): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_51): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_52): OnnxPReLU()\n",
       "  (Conv_53): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_54): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_55): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_56): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_57): OnnxPReLU()\n",
       "  (Conv_58): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_59): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_60): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_61): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_62): OnnxPReLU()\n",
       "  (Conv_63): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_64): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_65): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_66): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_67): OnnxPReLU()\n",
       "  (Conv_68): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_69): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_70): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_71): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_72): OnnxPReLU()\n",
       "  (Conv_73): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_74): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_75): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_76): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_77): OnnxPReLU()\n",
       "  (Conv_78): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_79): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_80): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_81): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_82): OnnxPReLU()\n",
       "  (Conv_83): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_84): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_85): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_86): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_87): OnnxPReLU()\n",
       "  (Conv_88): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_89): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_90): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_91): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_92): OnnxPReLU()\n",
       "  (Conv_93): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_94): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_95): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_96): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_97): OnnxPReLU()\n",
       "  (Conv_98): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_99): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_100): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_101): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_102): OnnxPReLU()\n",
       "  (Conv_103): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_104): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_105): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_106): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_107): OnnxPReLU()\n",
       "  (Conv_108): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_109): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_110): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_111): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_112): OnnxPReLU()\n",
       "  (Conv_113): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (Conv_114): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_115): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_116): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_117): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_118): OnnxPReLU()\n",
       "  (Conv_119): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_120): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_121): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_122): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_123): OnnxPReLU()\n",
       "  (Conv_124): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_125): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_126): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Flatten_127): Flatten(start_dim=1, end_dim=-1)\n",
       "  (Gemm_128): Linear(in_features=25088, out_features=512, bias=True)\n",
       "  (BatchNormalization_129): BatchNorm1d(512, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Усреднение эмбедингов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (Conv_0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (initializers): Module()\n",
       "  (PRelu_1): OnnxPReLU()\n",
       "  (BatchNormalization_2): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_4): OnnxPReLU()\n",
       "  (Conv_5): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (Conv_6): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_7): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_8): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_10): OnnxPReLU()\n",
       "  (Conv_11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_12): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_13): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_15): OnnxPReLU()\n",
       "  (Conv_16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_17): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_18): BatchNorm2d(64, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_19): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_20): OnnxPReLU()\n",
       "  (Conv_21): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (Conv_22): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_23): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_24): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_25): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_26): OnnxPReLU()\n",
       "  (Conv_27): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_28): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_29): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_30): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_31): OnnxPReLU()\n",
       "  (Conv_32): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_33): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_34): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_35): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_36): OnnxPReLU()\n",
       "  (Conv_37): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_38): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_39): BatchNorm2d(128, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_40): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_41): OnnxPReLU()\n",
       "  (Conv_42): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (Conv_43): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_44): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_45): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_46): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_47): OnnxPReLU()\n",
       "  (Conv_48): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_49): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_50): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_51): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_52): OnnxPReLU()\n",
       "  (Conv_53): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_54): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_55): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_56): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_57): OnnxPReLU()\n",
       "  (Conv_58): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_59): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_60): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_61): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_62): OnnxPReLU()\n",
       "  (Conv_63): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_64): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_65): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_66): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_67): OnnxPReLU()\n",
       "  (Conv_68): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_69): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_70): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_71): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_72): OnnxPReLU()\n",
       "  (Conv_73): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_74): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_75): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_76): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_77): OnnxPReLU()\n",
       "  (Conv_78): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_79): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_80): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_81): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_82): OnnxPReLU()\n",
       "  (Conv_83): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_84): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_85): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_86): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_87): OnnxPReLU()\n",
       "  (Conv_88): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_89): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_90): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_91): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_92): OnnxPReLU()\n",
       "  (Conv_93): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_94): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_95): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_96): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_97): OnnxPReLU()\n",
       "  (Conv_98): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_99): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_100): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_101): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_102): OnnxPReLU()\n",
       "  (Conv_103): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_104): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_105): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_106): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_107): OnnxPReLU()\n",
       "  (Conv_108): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_109): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_110): BatchNorm2d(256, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_111): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_112): OnnxPReLU()\n",
       "  (Conv_113): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (Conv_114): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "  (Add_115): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_116): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_117): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_118): OnnxPReLU()\n",
       "  (Conv_119): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_120): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_121): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Conv_122): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (PRelu_123): OnnxPReLU()\n",
       "  (Conv_124): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Add_125): OnnxBinaryMathOperation()\n",
       "  (BatchNormalization_126): BatchNorm2d(512, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       "  (Flatten_127): Flatten(start_dim=1, end_dim=-1)\n",
       "  (Gemm_128): Linear(in_features=25088, out_features=512, bias=True)\n",
       "  (BatchNormalization_129): BatchNorm1d(512, eps=9.999999747378752e-06, momentum=0.10000002384185791, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfw_vgg = []\n",
    "current_ind = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8631/8631 [2:24:41<00:00,  1.01s/it]  \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(len(labels_tuple[0]))):\n",
    "    with torch.no_grad():\n",
    "        batch_for_label = torch.cat([vgg_ds[current_ind + j][0][None, ...] for j in range(labels_tuple[1][i])]).to(\"cuda:0\")\n",
    "        emb_batch = torch_model(batch_for_label)\n",
    "        #print(emb_batch.shape)\n",
    "        mean_emb = torch.mean(emb_batch, dim = 0)\n",
    "    sfw_vgg.append(mean_emb.to(\"cpu\"))\n",
    "    current_ind += labels_tuple[1][i]\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfw_vgg_torch = torch.stack(sfw_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8631, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfw_vgg_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sfw_vgg_torch, \"/app/model_weights/backbone/vgg_iresnet50/softmax_weights_mean_vgg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfw_vgg_normalised = torch.nn.functional.normalize(sfw_vgg_torch, p=2.0, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sfw_vgg_normalised, \"/app/model_weights/backbone/vgg_iresnet50/softmax_weights_mean_vgg_normalised.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/face_lib/models/lightning_wrappers.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  backbone_dict = torch.load(weights)\n"
     ]
    }
   ],
   "source": [
    "### load model\n",
    "from face_lib.models.lightning_wrappers import ResNet\n",
    "\n",
    "backbone_old = ResNet(\n",
    "    \"iresnet50_normalized\",\n",
    "    \"/app/model_weights/backbone/ms1mv3_arcface_r50/backbone.pth\",\n",
    "    learnable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict emb\n",
    "# x = vgg_ds[0][0][None, ...]\n",
    "id = 0\n",
    "x = torch.cat([vgg_ds[2000][0][None, ...], vgg_ds[1][0][None, ...]])\n",
    "torch_model.to(\"cpu\")\n",
    "backbone_outputs = torch_model(x)\n",
    "backbone_outputs = torch.nn.functional.normalize(backbone_outputs, p=2.0, dim = 1)\n",
    "emb = backbone_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_ds[2000][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_852202/1228789056.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sfw_vgg_normalised = torch.load(\"/app/model_weights/backbone/vgg_iresnet50/softmax_weights_mean_vgg_normalised.pt\")\n"
     ]
    }
   ],
   "source": [
    "sfw_vgg_normalised = torch.load(\"/app/model_weights/backbone/vgg_iresnet50/softmax_weights_mean_vgg_normalised.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cos = []\n",
    "for weight in sfw_vgg_normalised:\n",
    "    cos.append(weight.detach().numpy() @ emb[0].detach().numpy())\n",
    "cos = np.array(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49048865\n"
     ]
    }
   ],
   "source": [
    "print(np.max(cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.790724"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1538214"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(cos)\n",
    "np.min(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3137807"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vgg_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Softmax Weights from model to separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1139223/632247186.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_trained = torch.load(\"/app/outputs/scf_new_data/arcface_vgg2/epoch=19-step=122560.ckpt\")\n"
     ]
    }
   ],
   "source": [
    "model_trained = torch.load(\"/app/outputs/scf_new_data/arcface_vgg2/epoch=19-step=122560.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trained.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_trained = model_trained[\"state_dict\"][\"softmax_weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sw_trained, \"/app/model_weights/backbone/vgg_iresnet50/softmax_weights_trained_correct.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing new softmax weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict emb\n",
    "# x = vgg_ds[0][0][None, ...]\n",
    "id = 0\n",
    "x = torch.cat([vgg_ds[2000347][0][None, ...], vgg_ds[1][0][None, ...]])\n",
    "torch_model.to(\"cpu\")\n",
    "backbone_new_outputs = torch_model(x)\n",
    "backbone_new_outputs = torch.nn.functional.normalize(backbone_new_outputs, p=2.0, dim = 1)\n",
    "backbone_old_outputs = backbone_old(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_trained = torch.nn.functional.normalize(sw_trained, p=2.0, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cos_new = []\n",
    "cos_old = []\n",
    "for weight in sw_trained:\n",
    "    cos_new.append(weight.detach().cpu().numpy() @ backbone_new_outputs[0].detach().cpu().numpy())\n",
    "    cos_old.append(weight.detach().cpu().numpy() @ backbone_old_outputs[\"feature\"][0].detach().cpu().numpy())\n",
    "cos_new = np.array(cos_new)\n",
    "cos_old = np.array(cos_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5460"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(cos_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38555342"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(cos_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024\n",
      "0.15234926\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(cos_old))\n",
    "print(np.max(cos_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(543)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_ds[200345][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in vgg_ds:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "            vgg_ds,\n",
    "            batch_size=512,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            num_workers=40,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6129/6129 [01:33<00:00, 65.75it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm.tqdm(dl):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим распределение получившихся косинусных расстояний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_ds = MXFaceDataset(\"/app/datasets/faces_vgg_112x112\")\n",
    "labels = np.load(\"/app/datasets/ms1m/labels.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
