{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import contextmanager, nullcontext\n",
    "\n",
    "from ax.utils.testing.mock import fast_botorch_optimize_context_manager\n",
    "import plotly.io as pio\n",
    "\n",
    "# Ax uses Plotly to produce interactive plots. These are great for viewing and analysis,\n",
    "# though they also lead to large file sizes, which is not ideal for files living in GH.\n",
    "# Changing the default to `png` strips the interactive components to get around this.\n",
    "pio.renderers.default = \"png\"\n",
    "\n",
    "SMOKE_TEST = False  # os.environ.get(\"SMOKE_TEST\")\n",
    "NUM_EVALS = 10  # if SMOKE_TEST else 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vis = np.array(\n",
    "    [\n",
    "        [0.5000, 4.0000, 0.2836],\n",
    "        [0.7531, 8.1725, 0.2831],\n",
    "        [0.4277, 2.9401, 0.2838],\n",
    "        [0.4394, 1.3498, 0.2838],\n",
    "        [0.3426, 2.0090, 0.2834],\n",
    "        [0.0000, 10.0000, 0.2829],\n",
    "        [0.4803, 1.7045, 0.2833],\n",
    "        [0.3379, 5.1669, 0.2836],\n",
    "        [0.8109, 0.8779, 0.2839],\n",
    "        [0.9960, 0.1000, 0.2825],\n",
    "        [0.6756, 1.7220, 0.2831],\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_X_vis = torch.tensor(data_vis[:, [0, 1]], dtype=torch.double)\n",
    "Y_vis = torch.tensor(data_vis[:, [2]], dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.models import ExactGP\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class SimpleCustomGP(ExactGP, GPyTorchModel):\n",
    "\n",
    "    _num_outputs = 1  # to inform GPyTorchModel API\n",
    "\n",
    "    def __init__(self, train_X, train_Y, train_Yvar: Optional[Tensor] = None):\n",
    "        # NOTE: This ignores train_Yvar and uses inferred noise instead.\n",
    "        # squeeze output dim before passing train_Y to ExactGP\n",
    "        super().__init__(train_X, train_Y.squeeze(-1), GaussianLikelihood())\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = ScaleKernel(\n",
    "            base_kernel=RBFKernel(ard_num_dims=train_X.shape[-1]),\n",
    "        )\n",
    "        self.to(train_X)  # make sure we're on the right device/dtype\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.models.torch.botorch_modular.model import BoTorchModel\n",
    "from ax.models.torch.botorch_modular.surrogate import Surrogate\n",
    "\n",
    "\n",
    "ax_model = BoTorchModel(\n",
    "    surrogate=Surrogate(\n",
    "        # The model class to use\n",
    "        botorch_model_class=SimpleCustomGP,\n",
    "        # Optional, MLL class with which to optimize model parameters\n",
    "        # mll_class=ExactMarginalLogLikelihood,\n",
    "        # Optional, dictionary of keyword arguments to model constructor\n",
    "        # model_options={}\n",
    "    ),\n",
    "    # Optional, acquisition function class to use - see custom acquisition tutorial\n",
    "    # botorch_acqf_class=qExpectedImprovement,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy\n",
    "from ax.modelbridge.registry import Models\n",
    "\n",
    "\n",
    "gs = GenerationStrategy(\n",
    "    steps=[\n",
    "        # Quasi-random initialization step\n",
    "        GenerationStep(\n",
    "            model=Models.SOBOL,\n",
    "            num_trials=4,  # How many trials should be produced from this generation step\n",
    "        ),\n",
    "        # Bayesian optimization step using the custom acquisition function\n",
    "        GenerationStep(\n",
    "            model=Models.BOTORCH_MODULAR,\n",
    "            num_trials=-1,  # No limitation on how many trials should be produced from this step\n",
    "            # For `BOTORCH_MODULAR`, we pass in kwargs to specify what surrogate or acquisition function to use.\n",
    "            model_kwargs={\n",
    "                \"surrogate\": Surrogate(SimpleCustomGP),\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-11 07:54:55] ax.service.ax_client: Starting optimization with verbose logging. To disable logging, set the `verbose_logging` argument to `False`. Note that float values in the logs are rounded to 6 decimal points.\n",
      "[INFO 10-11 07:54:55] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x1. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 10-11 07:54:55] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter x2. If that is not the expected value type, you can explicitly specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 10-11 07:54:55] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[RangeParameter(name='x1', parameter_type=FLOAT, range=[0.0, 1.0]), RangeParameter(name='x2', parameter_type=FLOAT, range=[0.0, 10.0])], parameter_constraints=[]).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.service.utils.instantiation import ObjectiveProperties\n",
    "from botorch.test_functions import Branin\n",
    "\n",
    "\n",
    "# Initialize the client - AxClient offers a convenient API to control the experiment\n",
    "ax_client = AxClient(generation_strategy=gs)\n",
    "# Setup the experiment\n",
    "ax_client.create_experiment(\n",
    "    name=\"branin_test_experiment\",\n",
    "    parameters=[\n",
    "        {\n",
    "            \"name\": \"x1\",\n",
    "            \"type\": \"range\",\n",
    "            # It is crucial to use floats for the bounds, i.e., 0.0 rather than 0.\n",
    "            # Otherwise, the parameter would be inferred as an integer range.\n",
    "            \"bounds\": [0.0, 1.0],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"x2\",\n",
    "            \"type\": \"range\",\n",
    "            \"bounds\": [0.0, 10.0],\n",
    "        },\n",
    "    ],\n",
    "    objectives={\n",
    "        \"branin\": ObjectiveProperties(minimize=True),\n",
    "    },\n",
    ")\n",
    "# Setup a function to evaluate the trials\n",
    "branin = Branin()\n",
    "\n",
    "\n",
    "def evaluate(parameters):\n",
    "    x = torch.tensor([[parameters.get(f\"x{i+1}\") for i in range(2)]])\n",
    "    # The GaussianLikelihood used by our model infers an observation noise level,\n",
    "    # so we pass an sem value of NaN to indicate that observation noise is unknown\n",
    "    return {\"branin\": (branin(x).item(), float(\"nan\"))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 10-11 07:54:58] ax.service.ax_client: Generated new trial 0 with parameters {'x1': 0.763879, 'x2': 3.519315} using model Sobol.\n",
      "[INFO 10-11 07:54:58] ax.service.ax_client: Completed trial 0 with data: {'branin': (18.730694, nan)}.\n",
      "[INFO 10-11 07:54:58] ax.service.ax_client: Generated new trial 1 with parameters {'x1': 0.881028, 'x2': 3.645018} using model Sobol.\n",
      "[INFO 10-11 07:54:58] ax.service.ax_client: Completed trial 1 with data: {'branin': (17.219318, nan)}.\n",
      "[INFO 10-11 07:54:58] ax.service.ax_client: Generated new trial 2 with parameters {'x1': 0.050301, 'x2': 5.257518} using model Sobol.\n",
      "[INFO 10-11 07:54:58] ax.service.ax_client: Completed trial 2 with data: {'branin': (20.029209, nan)}.\n",
      "[INFO 10-11 07:54:58] ax.service.ax_client: Generated new trial 3 with parameters {'x1': 0.425749, 'x2': 6.384849} using model Sobol.\n",
      "[INFO 10-11 07:54:58] ax.service.ax_client: Completed trial 3 with data: {'branin': (19.824518, nan)}.\n",
      "[INFO 10-11 07:54:58] ax.service.ax_client: Generated new trial 4 with parameters {'x1': 0.914266, 'x2': 7.497454} using model Sobol.\n",
      "[INFO 10-11 07:54:58] ax.service.ax_client: Completed trial 4 with data: {'branin': (23.95244, nan)}.\n",
      "[INFO 10-11 07:54:59] ax.service.ax_client: Generated new trial 5 with parameters {'x1': 0.852556, 'x2': 3.795712} using model BoTorch.\n",
      "[INFO 10-11 07:54:59] ax.service.ax_client: Completed trial 5 with data: {'branin': (17.204819, nan)}.\n",
      "[INFO 10-11 07:55:02] ax.service.ax_client: Generated new trial 6 with parameters {'x1': 0.909306, 'x2': 4.288168} using model BoTorch.\n",
      "[INFO 10-11 07:55:02] ax.service.ax_client: Completed trial 6 with data: {'branin': (16.036484, nan)}.\n",
      "[INFO 10-11 07:55:03] ax.service.ax_client: Generated new trial 7 with parameters {'x1': 0.0, 'x2': 8.57992} using model BoTorch.\n",
      "[INFO 10-11 07:55:03] ax.service.ax_client: Completed trial 7 with data: {'branin': (26.258099, nan)}.\n",
      "[INFO 10-11 07:55:03] ax.service.ax_client: Generated new trial 8 with parameters {'x1': 1.0, 'x2': 0.0} using model BoTorch.\n",
      "[INFO 10-11 07:55:03] ax.service.ax_client: Completed trial 8 with data: {'branin': (35.778175, nan)}.\n",
      "[INFO 10-11 07:55:04] ax.service.ax_client: Generated new trial 9 with parameters {'x1': 1.0, 'x2': 4.492138} using model BoTorch.\n",
      "[INFO 10-11 07:55:04] ax.service.ax_client: Completed trial 9 with data: {'branin': (15.190114, nan)}.\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning:\n",
      "\n",
      "Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "\n",
      "[INFO 10-11 07:55:11] ax.service.ax_client: Generated new trial 10 with parameters {'x1': 1.0, 'x2': 4.584825} using model BoTorch.\n",
      "[INFO 10-11 07:55:11] ax.service.ax_client: Completed trial 10 with data: {'branin': (15.190271, nan)}.\n",
      "[INFO 10-11 07:55:15] ax.service.ax_client: Generated new trial 11 with parameters {'x1': 1.0, 'x2': 4.539039} using model BoTorch.\n",
      "[INFO 10-11 07:55:15] ax.service.ax_client: Completed trial 11 with data: {'branin': (15.188046, nan)}.\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning:\n",
      "\n",
      "Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal')]\n",
      "Trying again with a new set of initial conditions.\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:389: RuntimeWarning:\n",
      "\n",
      "Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "\n",
      "[INFO 10-11 07:55:27] ax.service.ax_client: Generated new trial 12 with parameters {'x1': 1.0, 'x2': 4.633207} using model BoTorch.\n",
      "[INFO 10-11 07:55:27] ax.service.ax_client: Completed trial 12 with data: {'branin': (15.197178, nan)}.\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning:\n",
      "\n",
      "Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), NumericalWarning('A not p.d., added jitter of 1.0e-08 to the diagonal')]\n",
      "Trying again with a new set of initial conditions.\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:389: RuntimeWarning:\n",
      "\n",
      "Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "\n",
      "[INFO 10-11 07:55:35] ax.service.ax_client: Generated new trial 13 with parameters {'x1': 1.0, 'x2': 4.445436} using model BoTorch.\n",
      "[INFO 10-11 07:55:36] ax.service.ax_client: Completed trial 13 with data: {'branin': (15.196545, nan)}.\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning:\n",
      "\n",
      "Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:389: RuntimeWarning:\n",
      "\n",
      "Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "\n",
      "[INFO 10-11 07:55:51] ax.service.ax_client: Generated new trial 14 with parameters {'x1': 1.0, 'x2': 4.546104} using model BoTorch.\n",
      "[INFO 10-11 07:55:51] ax.service.ax_client: Completed trial 14 with data: {'branin': (15.188116, nan)}.\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning:\n",
      "\n",
      "Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:389: RuntimeWarning:\n",
      "\n",
      "Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "\n",
      "[INFO 10-11 07:56:05] ax.service.ax_client: Generated new trial 15 with parameters {'x1': 1.0, 'x2': 4.512809} using model BoTorch.\n",
      "[INFO 10-11 07:56:06] ax.service.ax_client: Completed trial 15 with data: {'branin': (15.188661, nan)}.\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning:\n",
      "\n",
      "Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:389: RuntimeWarning:\n",
      "\n",
      "Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "\n",
      "[INFO 10-11 07:56:28] ax.service.ax_client: Generated new trial 16 with parameters {'x1': 1.0, 'x2': 4.595097} using model BoTorch.\n",
      "[INFO 10-11 07:56:28] ax.service.ax_client: Completed trial 16 with data: {'branin': (15.191345, nan)}.\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning:\n",
      "\n",
      "Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:389: RuntimeWarning:\n",
      "\n",
      "Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "\n",
      "[INFO 10-11 07:56:44] ax.service.ax_client: Generated new trial 17 with parameters {'x1': 1.0, 'x2': 4.561864} using model BoTorch.\n",
      "[INFO 10-11 07:56:44] ax.service.ax_client: Completed trial 17 with data: {'branin': (15.188631, nan)}.\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning:\n",
      "\n",
      "Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:389: RuntimeWarning:\n",
      "\n",
      "Optimization failed on the second try, after generating a new set of initial conditions.\n",
      "\n",
      "[INFO 10-11 07:56:58] ax.service.ax_client: Generated new trial 18 with parameters {'x1': 1.0, 'x2': 4.476997} using model BoTorch.\n",
      "[INFO 10-11 07:56:58] ax.service.ax_client: Completed trial 18 with data: {'branin': (15.191721, nan)}.\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-08 to the diagonal\n",
      "\n",
      "/home/l.erlygin/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:367: RuntimeWarning:\n",
      "\n",
      "Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.'), OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL_TERMINATION_IN_LNSRCH.')]\n",
      "Trying again with a new set of initial conditions.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EVALS):\n\u001b[0;32m----> 2\u001b[0m     parameters, trial_index \u001b[38;5;241m=\u001b[39m \u001b[43max_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Local evaluation here can be replaced with deployment to external system.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     ax_client\u001b[38;5;241m.\u001b[39mcomplete_trial(trial_index\u001b[38;5;241m=\u001b[39mtrial_index, raw_data\u001b[38;5;241m=\u001b[39mevaluate(parameters))\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/utils/common/executils.py:161\u001b[0m, in \u001b[0;36mretry_on_exception.<locals>.func_wrapper.<locals>.actual_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m             wait_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m    158\u001b[0m                 MAX_WAIT_SECONDS, initial_wait_seconds \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    159\u001b[0m             )\n\u001b[1;32m    160\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(wait_interval)\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# If we are here, it means the retries were finished but\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# The error was suppressed. Hence return the default value provided.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m default_return_on_suppression\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/service/ax_client.py:531\u001b[0m, in \u001b[0;36mAxClient.get_next_trial\u001b[0;34m(self, ttl_seconds, force)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m OptimizationShouldStop(message\u001b[38;5;241m=\u001b[39mglobal_stopping_message)\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mnew_trial(\n\u001b[0;32m--> 531\u001b[0m         generator_run\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_new_generator_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, ttl_seconds\u001b[38;5;241m=\u001b[39mttl_seconds\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxParallelismReachedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_early_stopping_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/service/ax_client.py:1763\u001b[0m, in \u001b[0;36mAxClient._gen_new_generator_run\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1757\u001b[0m fixed_feats \u001b[38;5;241m=\u001b[39m InstantiationBase\u001b[38;5;241m.\u001b[39mmake_fixed_observation_features(\n\u001b[1;32m   1758\u001b[0m     fixed_features\u001b[38;5;241m=\u001b[39mFixedFeatures(\n\u001b[1;32m   1759\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m{}, trial_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_last_completed_trial_index()\n\u001b[1;32m   1760\u001b[0m     )\n\u001b[1;32m   1761\u001b[0m )\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m manual_seed(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_seed):\n\u001b[0;32m-> 1763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnot_none\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_strategy\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_pending_observation_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_feats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/modelbridge/generation_strategy.py:478\u001b[0m, in \u001b[0;36mGenerationStrategy.gen\u001b[0;34m(self, experiment, data, n, pending_observations, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen\u001b[39m(\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    445\u001b[0m     experiment: Experiment,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    450\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GeneratorRun:\n\u001b[1;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Produce the next points in the experiment. Additional kwargs passed to\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    this method are propagated directly to the underlying model's `gen`, along\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    with the `model_gen_kwargs` set on the current generation node.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;124;03m            resuggesting points that are currently being evaluated.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_multiple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_generator_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/modelbridge/generation_strategy.py:675\u001b[0m, in \u001b[0;36mGenerationStrategy._gen_multiple\u001b[0;34m(self, experiment, num_generator_runs, data, n, pending_observations, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generator_runs):\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 675\u001b[0m         generator_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_curr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m            \u001b[49m\u001b[43marms_by_signature_for_deduplication\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marms_by_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DataRequiredError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    683\u001b[0m         \u001b[38;5;66;03m# Model needs more data, so we log the error and return\u001b[39;00m\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;66;03m# as many generator runs as we were able to produce, unless\u001b[39;00m\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;66;03m# no trials were produced at all (in which case its safe to raise).\u001b[39;00m\n\u001b[1;32m    686\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(generator_runs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/modelbridge/generation_node.py:737\u001b[0m, in \u001b[0;36mGenerationStep.gen\u001b[0;34m(self, n, pending_observations, max_gen_draws_for_deduplication, arms_by_signature_for_deduplication, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen\u001b[39m(\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    731\u001b[0m     n: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_gen_kwargs: Any,\n\u001b[1;32m    736\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GeneratorRun:\n\u001b[0;32m--> 737\u001b[0m     gr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_gen_draws_for_deduplication\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_gen_draws_for_deduplication\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43marms_by_signature_for_deduplication\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marms_by_signature_for_deduplication\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m     gr\u001b[38;5;241m.\u001b[39m_generation_step_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gr\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/modelbridge/generation_node.py:307\u001b[0m, in \u001b[0;36mGenerationNode.gen\u001b[0;34m(self, n, pending_observations, max_gen_draws_for_deduplication, arms_by_signature_for_deduplication, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Keep generating until each of `generator_run.arms` is not a duplicate\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# of a previous arm, if `should_deduplicate is True`\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m should_generate_run:\n\u001b[0;32m--> 307\u001b[0m     generator_run \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# If `n` is not specified, ensure that the `None` value does not\u001b[39;49;00m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# override the one set in `model_spec.model_gen_kwargs`.\u001b[39;49;00m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# For `pending_observations`, prefer the input to this function, as\u001b[39;49;00m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# `pending_observations` are dynamic throughout the experiment and thus\u001b[39;49;00m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# unlikely to be specified in `model_spec.model_gen_kwargs`.\u001b[39;49;00m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     should_generate_run \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_deduplicate\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m arms_by_signature_for_deduplication\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m         )\n\u001b[1;32m    327\u001b[0m     )\n\u001b[1;32m    328\u001b[0m     n_gen_draws \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/modelbridge/model_spec.py:219\u001b[0m, in \u001b[0;36mModelSpec.gen\u001b[0;34m(self, **model_gen_kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m fitted_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted_model\n\u001b[1;32m    212\u001b[0m model_gen_kwargs \u001b[38;5;241m=\u001b[39m consolidate_kwargs(\n\u001b[1;32m    213\u001b[0m     kwargs_iterable\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_gen_kwargs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m     keywords\u001b[38;5;241m=\u001b[39mget_function_argument_names(fitted_model\u001b[38;5;241m.\u001b[39mgen),\n\u001b[1;32m    218\u001b[0m )\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfitted_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_gen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/modelbridge/base.py:784\u001b[0m, in \u001b[0;36mModelBridge.gen\u001b[0;34m(self, n, search_space, optimization_config, pending_observations, fixed_features, model_gen_options)\u001b[0m\n\u001b[1;32m    777\u001b[0m base_gen_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_transformed_gen_args(\n\u001b[1;32m    778\u001b[0m     search_space\u001b[38;5;241m=\u001b[39msearch_space,\n\u001b[1;32m    779\u001b[0m     optimization_config\u001b[38;5;241m=\u001b[39moptimization_config,\n\u001b[1;32m    780\u001b[0m     pending_observations\u001b[38;5;241m=\u001b[39mpending_observations,\n\u001b[1;32m    781\u001b[0m     fixed_features\u001b[38;5;241m=\u001b[39mfixed_features,\n\u001b[1;32m    782\u001b[0m )\n\u001b[1;32m    783\u001b[0m \u001b[38;5;66;03m# Apply terminal transform and gen\u001b[39;00m\n\u001b[0;32m--> 784\u001b[0m gen_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_gen_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_gen_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpending_observations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_gen_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpending_observations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_gen_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_gen_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_gen_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m observation_features \u001b[38;5;241m=\u001b[39m gen_results\u001b[38;5;241m.\u001b[39mobservation_features\n\u001b[1;32m    794\u001b[0m best_obsf \u001b[38;5;241m=\u001b[39m gen_results\u001b[38;5;241m.\u001b[39mbest_observation_features\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/modelbridge/torch.py:690\u001b[0m, in \u001b[0;36mTorchModelBridge._gen\u001b[0;34m(self, n, search_space, pending_observations, fixed_features, model_gen_options, optimization_config)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# Generate the candidates\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# TODO(ehotaj): For some reason, we're getting models which do not support MOO\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# even when optimization_config has multiple objectives, so we can't use\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# self.is_moo_problem here.\u001b[39;00m\n\u001b[1;32m    687\u001b[0m is_moo_problem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_moo_problem \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, (BoTorchModel, MultiObjectiveBotorchModel)\n\u001b[1;32m    689\u001b[0m )\n\u001b[0;32m--> 690\u001b[0m gen_results \u001b[38;5;241m=\u001b[39m \u001b[43mnot_none\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_space_digest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space_digest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_opt_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_opt_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m gen_metadata \u001b[38;5;241m=\u001b[39m gen_results\u001b[38;5;241m.\u001b[39mgen_metadata\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_moo_problem \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective_thresholds\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m gen_metadata:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;66;03m# If objective_thresholds are supplied by the user, then the transformed\u001b[39;00m\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# user-specified objective thresholds are in gen_metadata. Otherwise,\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;66;03m# if using a hypervolume based acquisition function, then\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;66;03m# the inferred objective thresholds are in gen_metadata.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/models/torch/botorch_modular/model.py:428\u001b[0m, in \u001b[0;36mBoTorchModel.gen\u001b[0;34m(self, n, search_space_digest, torch_opt_config)\u001b[0m\n\u001b[1;32m    422\u001b[0m acqf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instantiate_acquisition(\n\u001b[1;32m    423\u001b[0m     search_space_digest\u001b[38;5;241m=\u001b[39msearch_space_digest,\n\u001b[1;32m    424\u001b[0m     torch_opt_config\u001b[38;5;241m=\u001b[39mtorch_opt_config,\n\u001b[1;32m    425\u001b[0m     acq_options\u001b[38;5;241m=\u001b[39macq_options,\n\u001b[1;32m    426\u001b[0m )\n\u001b[1;32m    427\u001b[0m botorch_rounding_func \u001b[38;5;241m=\u001b[39m get_rounding_func(torch_opt_config\u001b[38;5;241m.\u001b[39mrounding_func)\n\u001b[0;32m--> 428\u001b[0m candidates, expected_acquisition_value \u001b[38;5;241m=\u001b[39m \u001b[43macqf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_space_digest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_space_digest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43minequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_to_inequality_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_opt_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_constraints\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_opt_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrounding_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbotorch_rounding_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecked_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m gen_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_gen_metadata_from_acqf(\n\u001b[1;32m    439\u001b[0m     acqf\u001b[38;5;241m=\u001b[39macqf,\n\u001b[1;32m    440\u001b[0m     torch_opt_config\u001b[38;5;241m=\u001b[39mtorch_opt_config,\n\u001b[1;32m    441\u001b[0m     expected_acquisition_value\u001b[38;5;241m=\u001b[39mexpected_acquisition_value,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TorchGenResults(\n\u001b[1;32m    444\u001b[0m     points\u001b[38;5;241m=\u001b[39mcandidates\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu(),\n\u001b[1;32m    445\u001b[0m     weights\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones(n, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m    446\u001b[0m     gen_metadata\u001b[38;5;241m=\u001b[39mgen_metadata,\n\u001b[1;32m    447\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/ax/models/torch/botorch_modular/acquisition.py:439\u001b[0m, in \u001b[0;36mAcquisition.optimize\u001b[0;34m(self, n, search_space_digest, inequality_constraints, fixed_features, rounding_func, optimizer_options)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# 1. Handle the fully continuous search space.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    436\u001b[0m     optimizer_options_with_defaults\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_use_optimize_acqf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m discrete_features\n\u001b[1;32m    438\u001b[0m ):\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43minequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_processing_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_processing_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptimizer_options_with_defaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# 2. Handle search spaces with discrete features.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m discrete_choices \u001b[38;5;241m=\u001b[39m mk_discrete_choices(ssd\u001b[38;5;241m=\u001b[39mssd, fixed_features\u001b[38;5;241m=\u001b[39mfixed_features)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:563\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[1;32m    541\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[1;32m    542\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[1;32m    543\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    561\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[1;32m    562\u001b[0m )\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:584\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:383\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initial_conditions_provided:\n\u001b[1;32m    370\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m opt_inputs\u001b[38;5;241m.\u001b[39mget_ic_generator()(\n\u001b[1;32m    371\u001b[0m         acq_function\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39macq_function,\n\u001b[1;32m    372\u001b[0m         bounds\u001b[38;5;241m=\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopt_inputs\u001b[38;5;241m.\u001b[39mic_gen_kwargs,\n\u001b[1;32m    381\u001b[0m     )\n\u001b[0;32m--> 383\u001b[0m     batch_candidates, batch_acq_values, ws \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_batch_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     optimization_warning_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    386\u001b[0m         (\u001b[38;5;28missubclass\u001b[39m(w\u001b[38;5;241m.\u001b[39mcategory, OptimizationWarning) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m ws)\n\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m optimization_warning_raised:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/botorch/optim/optimize.py:333\u001b[0m, in \u001b[0;36m_optimize_acqf_batch.<locals>._optimize_batch_candidates\u001b[0;34m()\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m ws:\n\u001b[1;32m    329\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mOptimizationWarning)\n\u001b[1;32m    330\u001b[0m     (\n\u001b[1;32m    331\u001b[0m         batch_candidates_curr,\n\u001b[1;32m    332\u001b[0m         batch_acq_values_curr,\n\u001b[0;32m--> 333\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_ics_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfiltered_gen_kwargs\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m opt_warnings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ws\n\u001b[1;32m    337\u001b[0m batch_candidates_list\u001b[38;5;241m.\u001b[39mappend(batch_candidates_curr)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/botorch/generation/gen.py:252\u001b[0m, in \u001b[0;36mgen_candidates_scipy\u001b[0;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features, timeout_sec)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(x):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39macquisition_function(x)\n\u001b[0;32m--> 252\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_with_timeout\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mf_np_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSLSQP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallback\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallback\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwith_grad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_sec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_sec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m _process_scipy_result(res\u001b[38;5;241m=\u001b[39mres, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    270\u001b[0m candidates \u001b[38;5;241m=\u001b[39m fix_features(\n\u001b[1;32m    271\u001b[0m     X\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfrom_numpy(res\u001b[38;5;241m.\u001b[39mx)\u001b[38;5;241m.\u001b[39mto(initial_conditions)\u001b[38;5;241m.\u001b[39mreshape(shapeX),\n\u001b[1;32m    272\u001b[0m     fixed_features\u001b[38;5;241m=\u001b[39mfixed_features,\n\u001b[1;32m    273\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/botorch/optim/utils/timeout.py:80\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[1;32m     77\u001b[0m     wrapped_callback \u001b[38;5;241m=\u001b[39m callback\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhessp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrapped_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OptimizationTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimization timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mruntime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/scipy/optimize/_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/botorch/generation/gen.py:211\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f_np_wrapper\u001b[0;34m(x, f)\u001b[0m\n\u001b[1;32m    209\u001b[0m loss \u001b[38;5;241m=\u001b[39m f(X_fix)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m gradf \u001b[38;5;241m=\u001b[39m _arrayify(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(gradf)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    213\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39misnan(gradf)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements of the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m element \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient array `gradf` are NaN. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis often indicates numerical issues.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/torch/autograd/__init__.py:436\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    432\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    433\u001b[0m         grad_outputs_\n\u001b[1;32m    434\u001b[0m     )\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 436\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    447\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    449\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EVALS):\n",
    "    parameters, trial_index = ax_client.get_next_trial()\n",
    "    # Local evaluation here can be replaced with deployment to external system.\n",
    "    ax_client.complete_trial(trial_index=trial_index, raw_data=evaluate(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, values = ax_client.get_best_parameters()\n",
    "print(f\"Best parameters: {parameters}\")\n",
    "print(f\"Corresponding mean: {values[0]}, covariance: {values[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.utils.notebook.plotting import render\n",
    "\n",
    "render(ax_client.get_contour_plot())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
