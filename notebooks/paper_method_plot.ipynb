{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "        p(\\textbf{z}|c) &= \\mathcal{C}_d(\\kappa)\\exp\\left(\\kappa\\mu^T_{c}\\textbf{z}\\right)\\\\\n",
    "        \\mathcal{C}_d(\\kappa) &= \\frac{(\\kappa)^{d/2-1}}{(2\\pi)^{d/2}\\mathcal{I}_{d/2-1}(\\kappa)}\n",
    "\\end{align}\n",
    "\n",
    "With d=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import iv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# mpl.style.use('classic')\n",
    "\n",
    "\n",
    "def z_Prob(z, mus, kappa, d=2, beta=0.5):\n",
    "    K = mus.shape[-1]\n",
    "    p_c = (1 - beta) / K\n",
    "    class_probs = np.array([z_vonMises_dencity(z, mu, kappa) for mu in mus.T])\n",
    "    return np.sum(class_probs * p_c) + (1 / (2 * np.pi)) * beta\n",
    "\n",
    "\n",
    "def z_class_prob(class_id, z, mus, kappa, d=2, beta=0.5):\n",
    "    p_z = z_Prob(z, mus, kappa, d, beta)\n",
    "    K = mus.shape[1]\n",
    "    if class_id == K:\n",
    "        p_c = beta\n",
    "        return (1 / (2 * np.pi)) * p_c / p_z\n",
    "    else:\n",
    "        p_c = (1 - beta) / K\n",
    "        return (z_vonMises_dencity(z, mus[:, class_id], kappa) * p_c) / p_z\n",
    "\n",
    "\n",
    "def z_vonMises_dencity(z, mu_c, kappa, d=2):\n",
    "    C_d = kappa ** (d / 2 - 1) / ((2 * np.pi) ** (d / 2) * iv(d / 2 - 1, kappa))\n",
    "    return C_d * np.exp(kappa * np.dot(z, mu_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_by_angle(angles):\n",
    "    return np.array([[np.cos(plot_angle), np.sin(plot_angle)] for plot_angle in angles])\n",
    "\n",
    "\n",
    "def compute_class_probs(class_id, zs, mus, kappa, beta):\n",
    "    class_probes = []\n",
    "    for z in zs:\n",
    "        class_prob = z_class_prob(class_id, z, mus, kappa, beta=beta)\n",
    "        class_probes.append(class_prob)\n",
    "    class_probes = np.array(class_probes)\n",
    "    return class_probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circle(ax, linewidth, zorder=4):\n",
    "    # plot circle\n",
    "    theta = np.linspace(0, 2 * np.pi, 150)\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    circle = plt.Circle((0, 0), 1, color=\"blue\", zorder=4, alpha=0.1)\n",
    "    ax.add_patch(circle)\n",
    "    ax.plot(a, b, color=\"tab:gray\", zorder=4, linewidth=linewidth)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "def draw_decity(ax):\n",
    "    pass\n",
    "\n",
    "\n",
    "def draw_example(kappa, gallery_class_angles, text_shift, save_name, beta=0.5):\n",
    "    fontsize = 20\n",
    "    linewidth = 3\n",
    "    dot_size = 80\n",
    "\n",
    "    test_color = \"tab:cyan\"\n",
    "    # gallery_class_angles = [0.4, 0.25]\n",
    "    ident_uncertain_test_point = (\n",
    "        gallery_class_angles[-1] + gallery_class_angles[-2]\n",
    "    ) / 2 - 0.02\n",
    "    test_points_angles = [\n",
    "        ident_uncertain_test_point,\n",
    "        gallery_class_angles[-1]\n",
    "        - (ident_uncertain_test_point - gallery_class_angles[-1]),\n",
    "    ]\n",
    "\n",
    "    gallery_class_angles = np.array(gallery_class_angles) * 2 * np.pi\n",
    "    test_points_angles = np.array(test_points_angles) * 2 * np.pi\n",
    "    theta = np.linspace(0, 2 * np.pi, 150)\n",
    "\n",
    "    colors = list(mcolors.TABLEAU_COLORS)[: len(gallery_class_angles)]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    draw_circle(ax, linewidth)\n",
    "\n",
    "    draw_dencity_angles = np.linspace(-np.pi / 3, np.pi / 3, 150)\n",
    "    mus = np.stack([np.cos(gallery_class_angles), np.sin(gallery_class_angles)], axis=0)\n",
    "    class_to_class_probs = []\n",
    "\n",
    "    for i, (angle, color) in enumerate(zip(gallery_class_angles, colors)):\n",
    "        mu_c = mus[:, i]\n",
    "        plot_angles = angle + draw_dencity_angles\n",
    "        zs = get_vectors_by_angle(plot_angles)\n",
    "        class_probes = compute_class_probs(i, zs, mus, kappa, beta)\n",
    "        v = zs.T * (1 + class_probes[np.newaxis, :])\n",
    "        ax.plot(v[0], v[1], c=color, linewidth=linewidth)\n",
    "\n",
    "        ax.scatter([np.cos(angle)], [np.sin(angle)], c=color, s=dot_size, zorder=5)\n",
    "        ax.scatter([0], [0], color=\"black\", s=20)\n",
    "\n",
    "        # plot decity\n",
    "        # ax.scatter(points[:, 0], points[:, 1], color=color, s=3)\n",
    "\n",
    "    # plot_uniform_prob\n",
    "    zs = get_vectors_by_angle(theta)\n",
    "    class_probes = compute_class_probs(mus.shape[1], zs, mus, kappa, beta)\n",
    "    v = zs.T * (1 + class_probes[np.newaxis, :])\n",
    "    # ax.plot(v[0], v[1], color='black')\n",
    "\n",
    "    # plot unc\n",
    "    all_probs = []\n",
    "    for i in range(mus.shape[1] + 1):\n",
    "        class_probes = compute_class_probs(i, zs, mus, kappa, beta)\n",
    "        all_probs.append(class_probes)\n",
    "    all_probs = np.stack(all_probs, axis=0)\n",
    "    unc = -np.sum(all_probs * np.log(all_probs), axis=0)\n",
    "    # unc = -np.max(all_probs, axis=0) + 1\n",
    "    v = zs.T * (1 + unc[np.newaxis, :])\n",
    "    ax.plot(v[0], v[1], color=\"tab:red\", linewidth=linewidth)\n",
    "\n",
    "    # plot test points\n",
    "    for test_angle in test_points_angles:\n",
    "        ax.scatter(\n",
    "            [np.cos(test_angle)],\n",
    "            [np.sin(test_angle)],\n",
    "            c=test_color,\n",
    "            s=dot_size,\n",
    "            zorder=5,\n",
    "        )\n",
    "\n",
    "    test_point_vectors = get_vectors_by_angle(test_points_angles)\n",
    "    # entropy value\n",
    "\n",
    "    probs_at_test_points = []\n",
    "    for i in range(mus.shape[1] + 1):\n",
    "        class_probes = compute_class_probs(i, test_point_vectors, mus, kappa, beta)\n",
    "        probs_at_test_points.append(class_probes)\n",
    "    probs_at_test_points = np.stack(probs_at_test_points, axis=0)\n",
    "\n",
    "    unc_test = -np.sum(probs_at_test_points * np.log(probs_at_test_points), axis=0)\n",
    "    unc_test = np.round(unc_test, 2)\n",
    "    # unc_test = -np.max(probs_at_test_points, axis=0) + 1\n",
    "    # unc_test = np.round(unc_test, 2)\n",
    "    ax.annotate(\n",
    "        f\"${unc_test[0]}$\",\n",
    "        xy=test_point_vectors[0],\n",
    "        xytext=[\n",
    "            test_point_vectors[0][0] + text_shift[0][0],\n",
    "            test_point_vectors[0][1] + text_shift[0][1],\n",
    "        ],\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "    ax.annotate(\n",
    "        f\"${unc_test[1]}$\",\n",
    "        xy=test_point_vectors[1],\n",
    "        xytext=[\n",
    "            test_point_vectors[1][0] + text_shift[1][0],\n",
    "            test_point_vectors[1][1] + text_shift[1][1],\n",
    "        ],\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "    fig.gca().set_aspect(\"equal\")\n",
    "    plt.savefig(save_name, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_example(\n",
    "#     kappa=15,\n",
    "#     gallery_class_angles=[0.4, 0.25],\n",
    "#     text_shift=[[-0.2, -0.3], [-0.2, 0.1]],\n",
    "#     save_name=\"test.png\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Identification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_example(kappa = 15, gallery_class_angles = [0.4, 0.25], text_shift = [[-0.2, -0.3], [-0.2, 0.1]], save_name='/app/paper_assets/images/false_ident_example.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False accept/reject example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_example(kappa = 13, gallery_class_angles = [0.48, 0.25], text_shift = [[-0.1, -0.3], [-0.35, 0.2]], save_name='/app/paper_assets/images/false_accept-reject_example.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vmf_dencity(\n",
    "    angle,\n",
    "    kappa,\n",
    "    ax,\n",
    "    linewidth,\n",
    "    color,\n",
    "    range=np.pi / 3,\n",
    "    scale=1,\n",
    "    draw_center=False,\n",
    "    dot_size=40,\n",
    "):\n",
    "    draw_dencity_angles = np.linspace(-range, range, 150)\n",
    "    plot_angles = angle + draw_dencity_angles\n",
    "    zs = get_vectors_by_angle(plot_angles)\n",
    "    mu = get_vectors_by_angle([angle])[0]\n",
    "    dencities = z_vonMises_dencity(zs, mu, kappa)\n",
    "    v = zs.T * (1 + dencities * scale)\n",
    "    ax.plot(v[0], v[1], c=color, linewidth=linewidth)\n",
    "    if draw_center:\n",
    "        ax.scatter([np.cos(angle)], [np.sin(angle)], c=color, s=dot_size, zorder=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.samplers import random_VMF, VonMisesFisher\n",
    "\n",
    "gallery_features = []  # N gallery samples X 512\n",
    "gallery_unc_log = []  # N gallery samples X 1\n",
    "gallery_subject_ids_sorted = []  # N gallery samples\n",
    "\n",
    "\n",
    "class_center_angles = np.array([0, np.pi / 2, np.pi])\n",
    "class_z_kappa = np.array([9, 6, 5])\n",
    "colors = list(mcolors.TABLEAU_COLORS)[: len(class_center_angles)]\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(2)\n",
    "for class_id, (angle, kappa) in enumerate(zip(class_center_angles, class_z_kappa)):\n",
    "    num_samples = rng.integers(3, 6)\n",
    "    gallery_subject_ids_sorted.extend([class_id] * num_samples)\n",
    "    gallery_unc_log.extend(3 * rng.random(num_samples) + 3)\n",
    "    samples = random_VMF(\n",
    "        get_vectors_by_angle([angle])[0], kappa=kappa, size=num_samples\n",
    "    )\n",
    "    gallery_features.extend(samples)\n",
    "\n",
    "gallery_features = np.array(gallery_features)\n",
    "gallery_unc_log = np.array(gallery_unc_log).reshape(-1, 1)\n",
    "gallery_subject_ids_sorted = np.array(gallery_subject_ids_sorted)\n",
    "\n",
    "gallery_unc = np.exp(gallery_unc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = VonMisesFisher(3)\n",
    "feature_mean = sampler(np.array([[0, 1], [1, 0]]), np.array([[10], [15]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fontsize = 20\n",
    "linewidth = 3\n",
    "dot_size = 80\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "draw_circle(ax, linewidth)\n",
    "for class_id, (angle, kappa) in enumerate(zip(class_center_angles, class_z_kappa)):\n",
    "    color = colors[class_id]\n",
    "    draw_vmf_dencity(angle, kappa, ax, linewidth=3, color=color, range=np.pi / 2)\n",
    "    for position in np.where(gallery_subject_ids_sorted == class_id)[0]:\n",
    "        point_angle = np.angle(\n",
    "            [gallery_features[position][0] + 1j * gallery_features[position][1]]\n",
    "        )[0]\n",
    "        draw_vmf_dencity(\n",
    "            point_angle,\n",
    "            gallery_unc[position],\n",
    "            ax,\n",
    "            linewidth=1,\n",
    "            color=color,\n",
    "            range=np.pi / 2,\n",
    "            scale=0.1,\n",
    "            draw_center=True,\n",
    "        )\n",
    "fig.gca().set_aspect(\"equal\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "gallery_features.shape\n",
    "init_mean = np.array(\n",
    "    [\n",
    "        np.mean(gallery_features[gallery_subject_ids_sorted == c], axis=0)\n",
    "        for c in range(3)\n",
    "    ]\n",
    ")\n",
    "# init_mean = init_mean / np.linalg.norm(init_mean, axis=1, keepdims=True)\n",
    "\n",
    "init_kappa = np.array(\n",
    "    [np.mean(gallery_unc[gallery_subject_ids_sorted == c], axis=0) for c in range(3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 2), (11, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gallery_features.shape, gallery_unc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from scipy.special import ive, hyp0f1, loggamma\n",
    "\n",
    "\n",
    "class MonteCarloPredictiveProb:\n",
    "    def __init__(\n",
    "        self,\n",
    "        M: int,\n",
    "        gallery_prior: str = \"power\",\n",
    "        unc_model: str = \"vMF\",\n",
    "        beta: float = 0.5,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        params:\n",
    "        M -- number of MC samples\n",
    "        gallery_prior -- model for p(z|c)\n",
    "        unc_model -- form of p(z|x)\n",
    "        \"\"\"\n",
    "        self.M = M\n",
    "        assert gallery_prior in [\"power\", \"vMF\"]\n",
    "        assert unc_model in [\"vMF\", \"PFE\"]\n",
    "        if unc_model == \"vMF\":\n",
    "            self.sampler = VonMisesFisher(self.M)\n",
    "        self.gallery_prior = gallery_prior\n",
    "        self.unc_model = unc_model\n",
    "        self.beta = beta\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        mean: np.array,\n",
    "        kappa: np.array,\n",
    "        gallery_means: torch.nn.Parameter,\n",
    "        gallery_kappas: torch.nn.Parameter,\n",
    "        T: torch.nn.Parameter,\n",
    "    ) -> Any:\n",
    "        self.K = gallery_means.shape[0]\n",
    "        # print(self.K)\n",
    "        zs = torch.tensor(self.sampler(mean, kappa))\n",
    "        d = torch.tensor([mean.shape[-1]])\n",
    "        # print(zs.shape, gallery_means.shape)\n",
    "        # print(zs, gallery_means)\n",
    "        similarities = zs @ gallery_means.T\n",
    "        # print(similarities.shape)\n",
    "        # print(similarities)\n",
    "        if self.gallery_prior == \"power\":\n",
    "            log_m_c_power = (\n",
    "                torch.special.gammaln(d - 1 + gallery_kappas)\n",
    "                + torch.special.gammaln(d / 2 + gallery_kappas)\n",
    "                + gallery_kappas * np.log(2)\n",
    "                - torch.special.gammaln(d / 2)\n",
    "                - torch.special.gammaln(d - 1 + 2 * gallery_kappas)\n",
    "            )\n",
    "            m_c_power = torch.exp(log_m_c_power)\n",
    "            log_uniform_dencity = (\n",
    "                torch.special.gammaln(d / 2) - np.log(2) - (d / 2) * np.log(np.pi)\n",
    "            )\n",
    "            log_normalizer = log_m_c_power + log_uniform_dencity\n",
    "        # compute log z prob\n",
    "        p_c = ((1 - self.beta) / self.K) ** (1 / T)\n",
    "        # print(similarities.shape, gallery_kappas.shape, log_uniform.shape, m_c_power.shape)\n",
    "        logit_sum = (\n",
    "            torch.sum(\n",
    "                (m_c_power[..., :, 0] ** (1 / T))\n",
    "                * ((1 + similarities) ** (gallery_kappas[..., :, 0] * (1 / T))),\n",
    "                dim=-1,\n",
    "            )\n",
    "            * p_c\n",
    "        )\n",
    "        log_z_prob = (1 / T) * log_uniform_dencity + torch.log(\n",
    "            logit_sum + (self.beta) ** (1 / T)\n",
    "        )\n",
    "\n",
    "        log_beta = np.log(self.beta)\n",
    "        # print(similarities.shape, gallery_kappas.shape)\n",
    "        uniform_log_prob = (1 / T) * (log_uniform_dencity + log_beta) - log_z_prob\n",
    "\n",
    "        # compute gallery classes log prob\n",
    "        pz_c = (\n",
    "            torch.log((1 + similarities)) * gallery_kappas[..., :, 0]\n",
    "            + log_normalizer[..., :, 0]\n",
    "        )\n",
    "        # print(pz_c.shape, log_z_prob.shape)\n",
    "        gallery_log_probs = (1 / T) * (\n",
    "            pz_c + np.log((1 - self.beta) / self.K)\n",
    "        ) - log_z_prob[..., np.newaxis]\n",
    "        # print(uniform_log_prob.shape)\n",
    "        log_probs = torch.cat(\n",
    "            [gallery_log_probs, uniform_log_prob[..., np.newaxis]], dim=-1\n",
    "        )\n",
    "        # print(log_probs.shape)\n",
    "        # print(torch.sum(log_probs, dim=-1))\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParametrizedGalleryParams(\n",
       "  (parametrizations): ModuleDict(\n",
       "    (gallery_means): ParametrizationList(\n",
       "      (0): Sphere(n=2, radius=1.0, tensorial_size=(3,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geotorch\n",
    "\n",
    "nll_loss = torch.nn.NLLLoss()\n",
    "\n",
    "\n",
    "class GalleryParams(torch.nn.Module):\n",
    "    def __init__(self, init_mean, init_kappa):\n",
    "        super(GalleryParams, self).__init__()\n",
    "        self.gallery_means = torch.nn.Parameter(torch.tensor(init_mean))\n",
    "        self.gallery_kappas = torch.nn.Parameter(torch.tensor(init_kappa))\n",
    "\n",
    "\n",
    "gallery_params = GalleryParams(init_mean, init_kappa)\n",
    "target_class = torch.tensor(gallery_subject_ids_sorted)\n",
    "T = torch.nn.Parameter(torch.tensor(1.0))\n",
    "geotorch.sphere(gallery_params, \"gallery_means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0094,  1.0000],\n",
      "        [ 0.9434,  0.3317],\n",
      "        [-0.8727, -0.4883]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 0, Loss: 5.984463149244649\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.8304,  0.5572],\n",
      "        [ 0.2598,  0.9657],\n",
      "        [-0.9678,  0.2519]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 1, Loss: 27.88423802572675\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9458, -0.3246],\n",
      "        [-0.6092,  0.7930],\n",
      "        [-0.8870,  0.4617]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 2, Loss: 4.940297664670143\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.7184, -0.6957],\n",
      "        [-0.9264,  0.3766],\n",
      "        [-0.9640,  0.2661]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 3, Loss: 9.281266969507131\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.7661, -0.6428],\n",
      "        [-0.9175,  0.3978],\n",
      "        [-0.9964, -0.0846]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 4, Loss: 16.009277448015965\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9405, -0.3397],\n",
      "        [-0.7321,  0.6812],\n",
      "        [-0.8910, -0.4541]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 5, Loss: 12.564714263153393\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9932,  0.1162],\n",
      "        [-0.3474,  0.9377],\n",
      "        [-0.6926, -0.7214]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 6, Loss: 5.71872351615109\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.8538,  0.5206],\n",
      "        [ 0.1464,  0.9892],\n",
      "        [-0.5135, -0.8581]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 7, Loss: 1.893031180650703\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.6421,  0.7666],\n",
      "        [ 0.4969,  0.8678],\n",
      "        [-0.4653, -0.8852]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 8, Loss: 3.1068794258873327\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.5296,  0.8483],\n",
      "        [ 0.6174,  0.7867],\n",
      "        [-0.5450, -0.8384]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 9, Loss: 7.2772852955669585\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.5879,  0.8089],\n",
      "        [ 0.5823,  0.8130],\n",
      "        [-0.6875, -0.7262]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 10, Loss: 9.266666110647147\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.7395,  0.6731],\n",
      "        [ 0.4164,  0.9092],\n",
      "        [-0.8280, -0.5608]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 11, Loss: 7.053585453092459\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.8981,  0.4397],\n",
      "        [ 0.1597,  0.9872],\n",
      "        [-0.9289, -0.3703]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 12, Loss: 3.8945857852409365\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9881,  0.1541],\n",
      "        [-0.1215,  0.9926],\n",
      "        [-0.9815, -0.1915]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 13, Loss: 1.6181633568784997\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9934, -0.1146],\n",
      "        [-0.3739,  0.9275],\n",
      "        [-0.9981, -0.0617]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 14, Loss: 1.3364284790268384\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9605, -0.2782],\n",
      "        [-0.5359,  0.8443],\n",
      "        [-0.9999, -0.0114]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 15, Loss: 3.3286297468242405\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9430, -0.3328],\n",
      "        [-0.6074,  0.7944],\n",
      "        [-0.9990, -0.0457]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 16, Loss: 3.7208807791960328\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9630, -0.2696],\n",
      "        [-0.5831,  0.8124],\n",
      "        [-0.9899, -0.1417]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 17, Loss: 4.706527381141936\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9929, -0.1187],\n",
      "        [-0.5110,  0.8596],\n",
      "        [-0.9632, -0.2686]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 18, Loss: 3.723473015127557\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9968,  0.0805],\n",
      "        [-0.3821,  0.9241],\n",
      "        [-0.9182, -0.3960]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 19, Loss: 1.9809150444034336\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9612,  0.2760],\n",
      "        [-0.2151,  0.9766],\n",
      "        [-0.8653, -0.5012]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 20, Loss: 1.2881148699684273\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.8998,  0.4363],\n",
      "        [-0.0498,  0.9988],\n",
      "        [-0.8141, -0.5807]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 21, Loss: 1.2175953670790316\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.8418,  0.5398],\n",
      "        [ 0.0850,  0.9964],\n",
      "        [-0.7877, -0.6161]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 22, Loss: 1.7005449947132483\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.8164,  0.5775],\n",
      "        [ 0.1744,  0.9847],\n",
      "        [-0.7770, -0.6295]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 23, Loss: 1.9319697405825251\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.8345,  0.5511],\n",
      "        [ 0.2033,  0.9791],\n",
      "        [-0.7894, -0.6139]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 24, Loss: 2.7861116974073448\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.8834,  0.4686],\n",
      "        [ 0.1783,  0.9840],\n",
      "        [-0.8156, -0.5786]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 25, Loss: 2.195862456772235\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9398,  0.3416],\n",
      "        [ 0.1176,  0.9931],\n",
      "        [-0.8460, -0.5331]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 26, Loss: 1.6881449477614252\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9788,  0.2049],\n",
      "        [ 0.0207,  0.9998],\n",
      "        [-0.8808, -0.4735]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 27, Loss: 1.1914615723922564\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9975,  0.0703],\n",
      "        [-0.0820,  0.9966],\n",
      "        [-0.9123, -0.4096]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 28, Loss: 1.0635337899623207\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9998, -0.0181],\n",
      "        [-0.1691,  0.9856],\n",
      "        [-0.9401, -0.3410]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 29, Loss: 1.2767011929885441\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9988, -0.0487],\n",
      "        [-0.2346,  0.9721],\n",
      "        [-0.9580, -0.2867]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 30, Loss: 1.6315251750972202\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9999, -0.0148],\n",
      "        [-0.2880,  0.9576],\n",
      "        [-0.9655, -0.2603]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 31, Loss: 1.9044411090922893\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9971,  0.0755],\n",
      "        [-0.3102,  0.9507],\n",
      "        [-0.9649, -0.2627]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 32, Loss: 1.7562095437750371\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9801,  0.1987],\n",
      "        [-0.3065,  0.9519],\n",
      "        [-0.9614, -0.2752]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 33, Loss: 1.4648923923856023\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9514,  0.3078],\n",
      "        [-0.2880,  0.9576],\n",
      "        [-0.9517, -0.3069]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 34, Loss: 1.0141449671472587\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9239,  0.3827],\n",
      "        [-0.2519,  0.9678],\n",
      "        [-0.9378, -0.3472]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 35, Loss: 1.3185327468006551\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9014,  0.4329],\n",
      "        [-0.1954,  0.9807],\n",
      "        [-0.9223, -0.3866]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 36, Loss: 1.1748002865006308\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.8979,  0.4402],\n",
      "        [-0.1355,  0.9908],\n",
      "        [-0.9051, -0.4253]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 37, Loss: 1.2373081029725652\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9143,  0.4050],\n",
      "        [-0.0766,  0.9971],\n",
      "        [-0.8893, -0.4573]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 38, Loss: 1.1559438196624363\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9388,  0.3444],\n",
      "        [-0.0217,  0.9998],\n",
      "        [-0.8737, -0.4865]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 39, Loss: 1.05434485737295\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9634,  0.2680],\n",
      "        [ 0.0137,  0.9999],\n",
      "        [-0.8639, -0.5036]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 40, Loss: 1.2179813193398865\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9825,  0.1865],\n",
      "        [ 0.0366,  0.9993],\n",
      "        [-0.8732, -0.4874]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 41, Loss: 1.0485833777669833\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9917,  0.1289],\n",
      "        [ 0.0389,  0.9992],\n",
      "        [-0.8841, -0.4673]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 42, Loss: 0.9691082209661168\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9943,  0.1068],\n",
      "        [ 0.0279,  0.9996],\n",
      "        [-0.8968, -0.4425]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 43, Loss: 1.1230402823186465\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9948,  0.1016],\n",
      "        [ 0.0069,  1.0000],\n",
      "        [-0.9078, -0.4195]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 44, Loss: 0.860224038154679\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9911,  0.1329],\n",
      "        [-0.0252,  0.9997],\n",
      "        [-0.9173, -0.3981]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 45, Loss: 1.250888083021349\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9832,  0.1826],\n",
      "        [-0.0651,  0.9979],\n",
      "        [-0.9258, -0.3781]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 46, Loss: 1.0468797727495625\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9697,  0.2443],\n",
      "        [-0.1075,  0.9942],\n",
      "        [-0.9291, -0.3699]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 47, Loss: 1.2400375191025192\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9561,  0.2929],\n",
      "        [-0.1497,  0.9887],\n",
      "        [-0.9276, -0.3735]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 48, Loss: 0.9739539952502249\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9502,  0.3116],\n",
      "        [-0.1869,  0.9824],\n",
      "        [-0.9218, -0.3877]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 49, Loss: 1.1043114760937665\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9492,  0.3146],\n",
      "        [-0.2185,  0.9758],\n",
      "        [-0.9138, -0.4062]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 50, Loss: 0.8997973165827591\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9566,  0.2913],\n",
      "        [-0.2415,  0.9704],\n",
      "        [-0.9025, -0.4308]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 51, Loss: 1.017272634392485\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9680,  0.2509],\n",
      "        [-0.2585,  0.9660],\n",
      "        [-0.8910, -0.4541]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 52, Loss: 0.961815546894892\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9749,  0.2225],\n",
      "        [-0.2714,  0.9625],\n",
      "        [-0.8820, -0.4713]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 53, Loss: 0.9818498769410753\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9806,  0.1960],\n",
      "        [-0.2804,  0.9599],\n",
      "        [-0.8754, -0.4834]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 54, Loss: 0.7964322744344653\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9814,  0.1918],\n",
      "        [-0.2851,  0.9585],\n",
      "        [-0.8755, -0.4833]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 55, Loss: 1.0058941352353417\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9776,  0.2107],\n",
      "        [-0.2865,  0.9581],\n",
      "        [-0.8786, -0.4775]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 56, Loss: 0.9861731716471667\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9725,  0.2327],\n",
      "        [-0.2828,  0.9592],\n",
      "        [-0.8839, -0.4676]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 57, Loss: 0.7884402527481449\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9690,  0.2470],\n",
      "        [-0.2768,  0.9609],\n",
      "        [-0.8961, -0.4439]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 58, Loss: 1.0152068308955557\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9654,  0.2609],\n",
      "        [-0.2675,  0.9635],\n",
      "        [-0.9062, -0.4229]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 59, Loss: 0.874436588109197\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9625,  0.2714],\n",
      "        [-0.2521,  0.9677],\n",
      "        [-0.9129, -0.4082]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 60, Loss: 0.841619687396052\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9643,  0.2650],\n",
      "        [-0.2323,  0.9726],\n",
      "        [-0.9197, -0.3926]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 61, Loss: 0.9244578296247409\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9681,  0.2506],\n",
      "        [-0.2094,  0.9778],\n",
      "        [-0.9290, -0.3700]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 62, Loss: 0.7725067936144696\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9689,  0.2475],\n",
      "        [-0.1876,  0.9822],\n",
      "        [-0.9368, -0.3498]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 63, Loss: 0.9453453678470343\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9657,  0.2595],\n",
      "        [-0.1638,  0.9865],\n",
      "        [-0.9423, -0.3348]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 64, Loss: 1.1471735853214027\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9640,  0.2661],\n",
      "        [-0.1436,  0.9896],\n",
      "        [-0.9443, -0.3291]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 65, Loss: 0.875481604560536\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9628,  0.2702],\n",
      "        [-0.1281,  0.9918],\n",
      "        [-0.9440, -0.3300]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 66, Loss: 0.748392186500427\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9685,  0.2492],\n",
      "        [-0.1165,  0.9932],\n",
      "        [-0.9408, -0.3389]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 67, Loss: 0.9515854386181313\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9755,  0.2201],\n",
      "        [-0.1141,  0.9935],\n",
      "        [-0.9337, -0.3580]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 68, Loss: 0.7970492686918991\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9745,  0.2244],\n",
      "        [-0.1193,  0.9929],\n",
      "        [-0.9241, -0.3821]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 69, Loss: 1.2360309020123834\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9691,  0.2465],\n",
      "        [-0.1277,  0.9918],\n",
      "        [-0.9110, -0.4124]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 70, Loss: 1.090170661937652\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9635,  0.2677],\n",
      "        [-0.1422,  0.9898],\n",
      "        [-0.8983, -0.4394]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 71, Loss: 0.9642727798968505\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9621,  0.2727],\n",
      "        [-0.1525,  0.9883],\n",
      "        [-0.8837, -0.4680]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 72, Loss: 0.8877808534016031\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9575,  0.2885],\n",
      "        [-0.1631,  0.9866],\n",
      "        [-0.8720, -0.4895]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 73, Loss: 0.84421652662114\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9587,  0.2844],\n",
      "        [-0.1731,  0.9849],\n",
      "        [-0.8706, -0.4920]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 74, Loss: 0.9386833877602263\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9622,  0.2723],\n",
      "        [-0.1831,  0.9831],\n",
      "        [-0.8742, -0.4856]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 75, Loss: 0.799631577083477\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9673,  0.2536],\n",
      "        [-0.1895,  0.9819],\n",
      "        [-0.8875, -0.4609]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 76, Loss: 1.0320857095237257\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9696,  0.2449],\n",
      "        [-0.1912,  0.9815],\n",
      "        [-0.9015, -0.4327]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 77, Loss: 1.3439475483416559\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9703,  0.2419],\n",
      "        [-0.1924,  0.9813],\n",
      "        [-0.9141, -0.4055]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 78, Loss: 1.045934491202109\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9715,  0.2371],\n",
      "        [-0.1883,  0.9821],\n",
      "        [-0.9172, -0.3985]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 79, Loss: 1.1328833023920428\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9770,  0.2133],\n",
      "        [-0.1804,  0.9836],\n",
      "        [-0.9163, -0.4006]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 80, Loss: 0.9976438049387549\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9792,  0.2030],\n",
      "        [-0.1751,  0.9845],\n",
      "        [-0.9150, -0.4034]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 81, Loss: 0.884460778028841\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9782,  0.2078],\n",
      "        [-0.1684,  0.9857],\n",
      "        [-0.9107, -0.4131]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 82, Loss: 0.806476948518127\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9775,  0.2110],\n",
      "        [-0.1559,  0.9878],\n",
      "        [-0.9068, -0.4215]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 83, Loss: 0.8409996792760108\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9720,  0.2352],\n",
      "        [-0.1493,  0.9888],\n",
      "        [-0.9089, -0.4170]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 84, Loss: 1.0283595729158228\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9670,  0.2547],\n",
      "        [-0.1445,  0.9895],\n",
      "        [-0.9107, -0.4131]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 85, Loss: 1.0741865578113834\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9676,  0.2526],\n",
      "        [-0.1454,  0.9894],\n",
      "        [-0.9112, -0.4120]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 86, Loss: 0.9219710791587876\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9690,  0.2470],\n",
      "        [-0.1465,  0.9892],\n",
      "        [-0.9142, -0.4052]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 87, Loss: 0.9452366262038953\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9717,  0.2364],\n",
      "        [-0.1480,  0.9890],\n",
      "        [-0.9141, -0.4054]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 88, Loss: 0.8558161488038677\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9757,  0.2191],\n",
      "        [-0.1492,  0.9888],\n",
      "        [-0.9184, -0.3957]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 89, Loss: 0.8381452230000984\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9729,  0.2311],\n",
      "        [-0.1590,  0.9873],\n",
      "        [-0.9205, -0.3907]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 90, Loss: 1.1549094399644666\n",
      "tensor([1., 1., 1.], dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9741,  0.2263],\n",
      "        [-0.1716,  0.9852],\n",
      "        [-0.9177, -0.3973]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 91, Loss: 0.7568089758837935\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9764,  0.2161],\n",
      "        [-0.1858,  0.9826],\n",
      "        [-0.9134, -0.4071]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 92, Loss: 0.9172206858588177\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9804,  0.1970],\n",
      "        [-0.1955,  0.9807],\n",
      "        [-0.9101, -0.4144]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 93, Loss: 0.8346908662298163\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9787,  0.2052],\n",
      "        [-0.2043,  0.9789],\n",
      "        [-0.9099, -0.4147]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 94, Loss: 1.0202786649671884\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9717,  0.2363],\n",
      "        [-0.2162,  0.9763],\n",
      "        [-0.9036, -0.4284]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 95, Loss: 1.0279348061791127\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9678,  0.2516],\n",
      "        [-0.2176,  0.9760],\n",
      "        [-0.9094, -0.4160]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 96, Loss: 0.9963881803939448\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9676,  0.2524],\n",
      "        [-0.2131,  0.9770],\n",
      "        [-0.9162, -0.4008]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 97, Loss: 0.8252732895658578\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9698,  0.2440],\n",
      "        [-0.2027,  0.9792],\n",
      "        [-0.9214, -0.3886]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 98, Loss: 0.8844397971778825\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "tensor([[ 0.9746,  0.2239],\n",
      "        [-0.1862,  0.9825],\n",
      "        [-0.9235, -0.3837]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Iteration 99, Loss: 0.9880107015074551\n",
      "tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "M = 5\n",
    "mc_prob = MonteCarloPredictiveProb(M=M)\n",
    "\n",
    "# optimizer = torch.optim.Adam([gallery_means, gallery_kappas], lr=10e-3)\n",
    "optimizer = torch.optim.Adam(gallery_params.parameters(), lr=10e-1)\n",
    "\n",
    "num_steps = 100\n",
    "\n",
    "for iter in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    # compute nll loss\n",
    "    log_probs = mc_prob(\n",
    "        gallery_features,\n",
    "        gallery_unc,\n",
    "        gallery_params.gallery_means,\n",
    "        gallery_params.gallery_kappas,\n",
    "        T,\n",
    "    )[:, :, :-1]\n",
    "    probs = torch.exp(log_probs)\n",
    "    mean_probs = torch.mean(probs, axis=1)\n",
    "    log_probs_new = torch.log(mean_probs)\n",
    "    loss = nll_loss(log_probs_new, target_class)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(gallery_params.gallery_means)\n",
    "    print(f\"Iteration {iter}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
