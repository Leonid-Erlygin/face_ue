{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.realpath(\"__file__\")))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from face_lib.datasets import IJBDataset, IJBCTest\n",
    "from face_lib.utils import cfg\n",
    "from face_lib.evaluation.feature_extractors import (\n",
    "    extract_features_head,\n",
    "    extract_features_gan,\n",
    "    extract_features_scale,\n",
    ")\n",
    "from face_lib import models as mlib, utils\n",
    "from face_lib.utils.imageprocessing import preprocess\n",
    "from face_lib.evaluation.distance_uncertainty_funcs import harmonic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71513e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "\n",
    "uncertainty_type = \"head\"\n",
    "# uncertainty_type = \"scale\"\n",
    "\n",
    "config_path = \"../configs/models/iresnet_ms1m_pfe_normalized.yaml\"\n",
    "# config_path = \"../configs/scale/02_sigm_mul_coef_selection/32.yaml\"\n",
    "\n",
    "checkpoint_path = \"/gpfs/data/gpfs0/k.fedyanin/space/models/pfe/normalized_pfe/sota.pth\"\n",
    "# checkpoint_path = \"/gpfs/data/gpfs0/k.fedyanin/space/models/scale/02_sigm_mul_selection/32/checkpoint.pth\"\n",
    "\n",
    "dataset_path = \"/gpfs/gpfs0/k.fedyanin/space/IJB/aligned_data_for_fusion/small\"\n",
    "protocol_path = \"/gpfs/gpfs0/k.fedyanin/space/IJB/IJB-C/protocols/archive\"\n",
    "# discriminator_path = \"/gpfs/data/gpfs0/k.fedyanin/space/GAN/stylegan.pth\"\n",
    "discriminator_path = None\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65075d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:\" + str(device_id))\n",
    "\n",
    "model_args = cfg.load_config(config_path)\n",
    "if uncertainty_type == \"head\":\n",
    "    backbone = mlib.model_dict[model_args.backbone[\"name\"]](\n",
    "        **utils.pop_element(model_args.backbone, \"name\")\n",
    "    )\n",
    "    head = mlib.heads[model_args.head.name](\n",
    "        **utils.pop_element(model_args.head, \"name\")\n",
    "    )\n",
    "elif uncertainty_type == \"scale\":\n",
    "    backbone = mlib.model_dict[model_args.backbone[\"name\"]](\n",
    "        **utils.pop_element(model_args.backbone, \"name\")\n",
    "    )\n",
    "    head = mlib.scale_predictors[model_args.scale_predictor.name](\n",
    "        **utils.pop_element(model_args.scale_predictor, \"name\")\n",
    "    )\n",
    "else:\n",
    "    raise RuntimeError(\"Choose the right uncertainty_type\")\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "backbone.load_state_dict(checkpoint[\"backbone\"])\n",
    "\n",
    "if uncertainty_type == \"head\":\n",
    "    head.load_state_dict(checkpoint[\"head\"])\n",
    "elif uncertainty_type == \"scale\":\n",
    "    head.load_state_dict(checkpoint[\"scale_predictor\"])\n",
    "\n",
    "backbone, head = backbone.eval().to(device), head.eval().to(device)\n",
    "\n",
    "discriminator = None\n",
    "if discriminator_path:\n",
    "    discriminator = mlib.StyleGanDiscriminator()\n",
    "    discriminator.load_state_dict(torch.load(discriminator_path)[\"d\"])\n",
    "    discriminator.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = IJBDataset(dataset_path)\n",
    "tester = IJBCTest(testset[\"abspath\"].values)\n",
    "tester.init_proto(protocol_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_func = lambda images: preprocess(images, [112, 112], is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cdda6a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if uncertainty_type == \"head\":\n",
    "    with torch.no_grad():\n",
    "        mu, sigma_sq = extract_features_head(\n",
    "            backbone,\n",
    "            head,\n",
    "            tester.image_paths,\n",
    "            batch_size,\n",
    "            proc_func=proc_func,\n",
    "            verbose=False,\n",
    "            device=device,\n",
    "        )\n",
    "elif uncertainty_type == \"gan\":\n",
    "    with torch.no_grad():\n",
    "        mu, sigma_sq = extract_features_gan(\n",
    "            backbone,\n",
    "            discriminator,\n",
    "            tester.image_paths,\n",
    "            batch_size,\n",
    "            proc_func=proc_func,\n",
    "            verbose=False,\n",
    "            device=device,\n",
    "        )\n",
    "elif uncertainty_type == \"scale\":\n",
    "    with torch.no_grad():\n",
    "        mu, sigma_sq = extract_features_scale(\n",
    "            backbone,\n",
    "            head,\n",
    "            tester.image_paths,\n",
    "            batch_size,\n",
    "            proc_func=proc_func,\n",
    "            verbose=False,\n",
    "            device=device,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f78a6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uncertainties = harmonic_mean(sigma_sq)\n",
    "# uncertainties = np.arange(len(tester.image_paths))\n",
    "# uncertainties = sigma_sq[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9003ae0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(uncertainties)\n",
    "new_mus = mu[indices]\n",
    "new_sigmas = sigma_sq[indices]\n",
    "paths = tester.image_paths[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db0de5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_picture(path, ax):\n",
    "    #     print(f\"Path : {path}\")\n",
    "    pic = imageio.imread(path)\n",
    "    ax.imshow(pic)\n",
    "\n",
    "\n",
    "def show_pics_quantiles(sorted_paths, n_groups=10, n_pics=5, save_path=None):\n",
    "    fig, axes = plt.subplots(n_groups, n_pics, figsize=(30, 30))\n",
    "\n",
    "    for quantile_idx in range(n_groups):\n",
    "        left_idx = int(quantile_idx / n_groups * len(sorted_paths))\n",
    "        right_idx = int((quantile_idx + 1) / n_groups * len(sorted_paths))\n",
    "\n",
    "        picture_paths = random.sample(list(sorted_paths[left_idx:right_idx]), k=n_pics)\n",
    "        #         print(picture_paths, left_idx, right_idx)\n",
    "        for pic_path, ax in zip(picture_paths, axes[quantile_idx]):\n",
    "            #             print (pic_path.shape, pic_path[0])\n",
    "            show_picture(pic_path, ax)\n",
    "\n",
    "    names = [\n",
    "        str(quantile_idx / n_groups * 100)\n",
    "        + \"-\"\n",
    "        + str((quantile_idx + 1) / n_groups * 100)\n",
    "        + \"%\"\n",
    "        for quantile_idx in range(n_groups)\n",
    "    ]\n",
    "    pad = 20\n",
    "    for ax, row in zip(axes[:, 0], names):\n",
    "        ax.annotate(\n",
    "            row,\n",
    "            xy=(0, 0.5),\n",
    "            xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "            xycoords=ax.yaxis.label,\n",
    "            textcoords=\"offset points\",\n",
    "            size=\"large\",\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f305bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "    show_pics_quantiles(\n",
    "        paths,\n",
    "        n_groups=10,\n",
    "        n_pics=10,\n",
    "        save_path=f\"/beegfs/home/r.kail/faces/figures/14_sorted_faces/pfe/{idx}.pdf\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56074174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
