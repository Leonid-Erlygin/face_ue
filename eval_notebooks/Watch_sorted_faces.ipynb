{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.realpath(\"__file__\")))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from face_lib.datasets import IJBDataset, IJBCTest\n",
    "from face_lib.utils import cfg\n",
    "from face_lib.utils.feature_extractors import extract_features_head, extract_features_gan\n",
    "from face_lib import models as mlib, utils\n",
    "from face_lib.utils.imageprocessing import preprocess\n",
    "from face_lib.utils.utils import harmonic_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "\n",
    "config_path = \"../configs/models/iresnet_ms1m_probface.yaml\"\n",
    "checkpoint_path = \"/gpfs/gpfs0/r.zainulin/sota.pth\"\n",
    "dataset_path = \"/gpfs/gpfs0/k.fedyanin/space/IJB/aligned_data_for_fusion/big\"\n",
    "protocol_path = \"/gpfs/gpfs0/k.fedyanin/space/IJB/IJB-C/protocols/archive\"\n",
    "# discriminator_path = \"/gpfs/data/gpfs0/k.fedyanin/space/GAN/stylegan.pth\"\n",
    "discriminator_path = None\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:\" + str(device_id))\n",
    "\n",
    "model_args = cfg.load_config(config_path)\n",
    "backbone = mlib.model_dict[model_args.backbone[\"name\"]](\n",
    "    **utils.pop_element(model_args.backbone, \"name\")\n",
    ")\n",
    "head = mlib.heads[model_args.head.name](\n",
    "    **utils.pop_element(model_args.head, \"name\")\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "backbone.load_state_dict(checkpoint[\"backbone\"])\n",
    "head.load_state_dict(checkpoint[\"head\"])\n",
    "\n",
    "backbone, head = backbone.eval().to(device), head.eval().to(device)\n",
    "\n",
    "discriminator = None\n",
    "if discriminator_path:\n",
    "    discriminator = mlib.StyleGanDiscriminator()\n",
    "    discriminator.load_state_dict(torch.load(discriminator_path)[\"d\"])\n",
    "    discriminator.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identities :  3529\n",
      "31316978 templates are initialized.\n"
     ]
    }
   ],
   "source": [
    "testset = IJBDataset(dataset_path)\n",
    "tester = IJBCTest(testset[\"abspath\"].values)\n",
    "tester.init_proto(protocol_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_func = lambda images: preprocess(images, [112, 112], is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu, sigma_sq = extract_features_head(\n",
    "    backbone,\n",
    "    head,\n",
    "    tester.image_paths,\n",
    "    batch_size,\n",
    "    proc_func=proc_func,\n",
    "    verbose=True,\n",
    "    device=device,\n",
    ")\n",
    "# with torch.no_grad():\n",
    "#     mu, sigma_sq = extract_features_gan(\n",
    "#         backbone,\n",
    "#         discriminator,\n",
    "#         tester.image_paths,\n",
    "#         batch_size,\n",
    "#         proc_func=proc_func,\n",
    "#         verbose=True,\n",
    "#         device=device,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# uncertainties = harmonic_mean(sigma_sq)\n",
    "# uncertainties = np.arange(len(tester.image_paths))\n",
    "uncertainties = sigma_sq[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(uncertainties)\n",
    "new_mus = mu[indices]\n",
    "new_sigmas = sigma_sq[indices]\n",
    "paths = tester.image_paths[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_picture(path, ax):\n",
    "    pic = imageio.imread(path)\n",
    "    ax.imshow(pic)\n",
    "    \n",
    "def show_pics_quantiles(sorted_paths, n_groups=10, n_pics=5, save_path=None):\n",
    "    fig, axes = plt.subplots(n_groups, n_pics, figsize=(30, 30))\n",
    "    \n",
    "    for quantile_idx in range(n_groups):\n",
    "        left_idx = int(quantile_idx / n_groups * len(sorted_paths))\n",
    "        right_idx = int((quantile_idx + 1) / n_groups * len(sorted_paths))\n",
    "        \n",
    "        picture_paths = random.sample(list(sorted_paths[left_idx: right_idx]), k=n_pics)\n",
    "        print(picture_paths, left_idx, right_idx)\n",
    "        for pic_path, ax in zip(picture_paths, axes[quantile_idx]):\n",
    "            print (pic_path.shape, pic_path[0])\n",
    "            show_picture(pic_path[0], ax)\n",
    "            \n",
    "    names = [str(quantile_idx / n_groups * 100) + \"-\" + str((quantile_idx + 1) / n_groups * 100) + \"%\" for quantile_idx in range(n_groups)]\n",
    "    pad = 20\n",
    "    for ax, row in zip(axes[:, 0], names):\n",
    "        ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                    xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                    size='large', ha='right', va='center')\n",
    "        \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1):\n",
    "    print (f\"/gpfs/data/gpfs0/r.kail/figures/face_figs/gan_{idx}.png\")\n",
    "    show_pics_quantiles(paths, n_groups=10, n_pics=10, save_path=f\"/gpfs/data/gpfs0/r.kail/figures/face_figs/gan_{idx}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}