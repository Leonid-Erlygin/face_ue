{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d16bd34-6e1b-4de7-a48c-cbd69b4bb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f41996a-a2f6-4beb-91e5-7c00267b9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/gpfs/data/gpfs0/k.fedyanin/space/IJB/aligned_data_for_fusion/big\"\n",
    "RESULT_META_DIR = \"/gpfs/data/gpfs0/k.fedyanin/space/IJB/aligned_data_for_fusion/metadata_refuse_verification/val_test\"\n",
    "\n",
    "val_portion = 0.5\n",
    "NUM_PAIRS = 1000\n",
    "POSITIVE_PORTION = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51084c26-8a83-4aa4-8050-083611b10c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identities_split(dataset_path=dataset_path, val_portion=val_portion):\n",
    "    identities = np.array(os.listdir(dataset_path), dtype=object)\n",
    "    \n",
    "    np.random.shuffle(identities)\n",
    "    split_idx = int(val_portion * len(identities))\n",
    "    \n",
    "    return identities[:split_idx], identities[split_idx:]\n",
    "\n",
    "def randomized_round(number):\n",
    "    return int(number) + int(random.random() < (number % 1))\n",
    "\n",
    "def sample_pairs_from_directory(prefix, directory, n_pairs):\n",
    "    pairs = list(combinations(os.listdir(os.path.join(prefix, directory)), r=2))\n",
    "    n_sampled_pairs = n_pairs if n_pairs < len(pairs) else len(pairs)\n",
    "    pairs = [tuple(map(lambda x: os.path.join(directory, x), pair)) for pair in pairs]\n",
    "    return random.sample(pairs, n_sampled_pairs)\n",
    "\n",
    "\n",
    "def generate_positive_pairs(directories, n_pairs, identities_dir=dataset_path):\n",
    "\n",
    "    remaining_directories = len(directories)\n",
    "    remaining_pairs = n_pairs\n",
    "\n",
    "    positive_pairs = []\n",
    "    probes = []\n",
    "\n",
    "    random.shuffle(directories)\n",
    "    \n",
    "    mean_pairs_from_directory = n_pairs / len(directories)\n",
    "    sampled_pairs = 0\n",
    "    \n",
    "    for idx, directory in tqdm(enumerate(directories)):\n",
    "        lack = idx * mean_pairs_from_directory - sampled_pairs\n",
    "        lack = max(0, lack)\n",
    "        \n",
    "        needed_pairs_amount = randomized_round(lack + mean_pairs_from_directory)\n",
    "        probes.append(needed_pairs_amount)\n",
    "        new_pairs = sample_pairs_from_directory(identities_dir, directory, needed_pairs_amount)\n",
    "        positive_pairs.extend(new_pairs)\n",
    "\n",
    "        sampled_pairs += len(new_pairs)\n",
    "        \n",
    "    return positive_pairs\n",
    "\n",
    "\n",
    "def generate_negative_pairs(identities, n_pairs, identities_dir=dataset_path):\n",
    "    negative_pairs = set()\n",
    "    \n",
    "    identities = list(identities)\n",
    "    i = 0\n",
    "    while len(negative_pairs) < n_pairs:\n",
    "        left, right = random.sample(identities, 2)\n",
    "        potential_lefts = os.listdir(os.path.join(identities_dir, left))\n",
    "        potential_rights = os.listdir(os.path.join(identities_dir, right))\n",
    "        \n",
    "        if len(potential_lefts) and len(potential_rights):\n",
    "            left = os.path.join(left, random.choice(potential_lefts))\n",
    "            right = os.path.join(right, random.choice(potential_rights))\n",
    "            negative_pairs.add((left, right,))\n",
    "            \n",
    "        if i % 1000 == 0:\n",
    "            sys.stdout.write(\"Sampled pairs : {}/{}...\\t\\r\".format(len(negative_pairs), n_pairs))\n",
    "    return list(negative_pairs)\n",
    "\n",
    "def save_to_file(positive_pairs, negative_pairs, file_path):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for pair in positive_pairs:\n",
    "            f.write(\",\".join((pair[0], pair[1], \"1\")) + \"\\n\")\n",
    "        for pair in negative_pairs:\n",
    "            f.write(\",\".join((pair[0], pair[1], \"0\")) + \"\\n\")\n",
    "    \n",
    "\n",
    "def save_meta_file():\n",
    "    val_idxes, test_idxes = get_identities_split(dataset_path=dataset_path, val_portion=val_portion)\n",
    "    \n",
    "    val_path = os.path.join(RESULT_META_DIR, \"val_pairs_\" + str(NUM_PAIRS) + \"_prob_\" + str(POSITIVE_PORTION) + \".csv\")\n",
    "    pos_pairs = generate_positive_pairs(val_idxes, n_pairs=int(NUM_PAIRS * POSITIVE_PORTION))\n",
    "    neg_pairs = generate_negative_pairs(val_idxes, n_pairs=int(NUM_PAIRS * (1 - POSITIVE_PORTION)))\n",
    "    save_to_file(pos_pairs, neg_pairs, file_path=val_path)\n",
    "    \n",
    "    test_path = os.path.join(RESULT_META_DIR, \"test_pairs_\" + str(NUM_PAIRS) + \"_prob_\" + str(POSITIVE_PORTION) + \".csv\")\n",
    "    pos_pairs = generate_positive_pairs(test_idxes, n_pairs=int(NUM_PAIRS * POSITIVE_PORTION))\n",
    "    neg_pairs = generate_negative_pairs(test_idxes, n_pairs=int(NUM_PAIRS * (1 - POSITIVE_PORTION)))\n",
    "    save_to_file(pos_pairs, neg_pairs, file_path=test_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abede4b9-916a-44ef-a154-bbe992cbed27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1765it [00:12, 144.30it/s]\n",
      "57it [00:00, 560.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled pairs : 500/500...\t\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1766it [00:05, 347.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled pairs : 500/500...\t\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_meta_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
