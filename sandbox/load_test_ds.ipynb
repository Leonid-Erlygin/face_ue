{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import ndarray as nd\n",
    "sys.path.append('/app/sandbox/AdaFace')\n",
    "from AdaFace.data import test_dataset\n",
    "from AdaFace.evaluate_utils import get_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bin(path, image_size=[112,112]):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            bins, issame_list = pickle.load(f)  # py2\n",
    "    except UnicodeDecodeError as e:\n",
    "        with open(path, 'rb') as f:\n",
    "            bins, issame_list = pickle.load(f, encoding='bytes')  # py3\n",
    "    data_list = []\n",
    "    for flip in [0, 1]:\n",
    "        data = torch.empty((len(issame_list) * 2, 3, image_size[0], image_size[1]))\n",
    "        data_list.append(data)\n",
    "    for idx in range(len(issame_list) * 2):\n",
    "        _bin = bins[idx]\n",
    "        img = mx.image.imdecode(_bin)\n",
    "        if img.shape[1] != image_size[0]:\n",
    "            img = mx.image.resize_short(img, image_size[0])\n",
    "        img = nd.transpose(img, axes=(2, 0, 1))\n",
    "        for flip in [0, 1]:\n",
    "            if flip == 1:\n",
    "                img = mx.ndarray.flip(data=img, axis=2)\n",
    "            data_list[flip][idx][:] = torch.from_numpy(img.asnumpy())\n",
    "        if idx % 1000 == 0:\n",
    "            print('loading bin', idx)\n",
    "    print(data_list[0].shape)\n",
    "    return data_list, issame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading bin 0\n",
      "loading bin 1000\n",
      "loading bin 2000\n",
      "loading bin 3000\n",
      "loading bin 4000\n",
      "loading bin 5000\n",
      "loading bin 6000\n",
      "loading bin 7000\n",
      "loading bin 8000\n",
      "loading bin 9000\n",
      "loading bin 10000\n",
      "loading bin 11000\n",
      "torch.Size([12000, 3, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "data_set = load_bin('/app/datasets/ms1m/agedb_30.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 3000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set[1]), np.sum(data_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12000, 3, 112, 112])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/app/datasets'\n",
    "val_data_path = 'ms1m'\n",
    "val_data = get_val_data(os.path.join(data_root, val_data_path))\n",
    "# theses datasets are already normalized with mean 0.5, std 0.5\n",
    "age_30, cfp_fp, lfw, age_30_issame, cfp_fp_issame, lfw_issame, cplfw, cplfw_issame, calfw, calfw_issame = val_data\n",
    "val_data_dict = {\n",
    "    'agedb_30': (age_30, age_30_issame),\n",
    "    \"cfp_fp\": (cfp_fp, cfp_fp_issame),\n",
    "    \"lfw\": (lfw, lfw_issame),\n",
    "    \"cplfw\": (cplfw, cplfw_issame),\n",
    "    \"calfw\": (calfw, calfw_issame),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 3, 112, 112)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_dict['agedb_30'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 3000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data_dict['agedb_30'][1]), np.sum(val_data_dict['agedb_30'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.array(data_set[1]) == val_data_dict['agedb_30'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/app/datasets/ms1m/cfp_fp/meta/sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/app/datasets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mms1m\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/sandbox/AdaFace/data.py:175\u001b[0m, in \u001b[0;36mtest_dataset\u001b[0;34m(data_root, val_data_path, concat_mem_file_name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_dataset\u001b[39m(data_root, val_data_path, concat_mem_file_name):\n\u001b[0;32m--> 175\u001b[0m     val_data \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_val_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;66;03m# theses datasets are already normalized with mean 0.5, std 0.5\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     age_30, cfp_fp, lfw, age_30_issame, cfp_fp_issame, lfw_issame, cplfw, cplfw_issame, calfw, calfw_issame \u001b[38;5;241m=\u001b[39m val_data\n",
      "File \u001b[0;32m/app/sandbox/AdaFace/evaluate_utils.py:13\u001b[0m, in \u001b[0;36mget_val_data\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_val_data\u001b[39m(data_path):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#agedb_30, agedb_30_issame = get_val_pair(data_path, 'agedb_30')\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     cfp_fp, cfp_fp_issame \u001b[38;5;241m=\u001b[39m \u001b[43mget_val_pair\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcfp_fp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     lfw, lfw_issame \u001b[38;5;241m=\u001b[39m get_val_pair(data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlfw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     cplfw, cplfw_issame \u001b[38;5;241m=\u001b[39m get_val_pair(data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcplfw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/app/sandbox/AdaFace/evaluate_utils.py:28\u001b[0m, in \u001b[0;36mget_val_pair\u001b[0;34m(path, name, use_memfile)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(mem_file_dir)\n\u001b[0;32m---> 28\u001b[0m     carray \u001b[38;5;241m=\u001b[39m \u001b[43mbcolz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrootdir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     np_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(carray)\n\u001b[1;32m     30\u001b[0m     mem_array \u001b[38;5;241m=\u001b[39m make_memmap(mem_file_name, np_array)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/bcolz/carray_ext.pyx:1067\u001b[0m, in \u001b[0;36mbcolz.carray_ext.carray.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/bcolz/carray_ext.pyx:1369\u001b[0m, in \u001b[0;36mbcolz.carray_ext.carray._read_meta\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/app/datasets/ms1m/cfp_fp/meta/sizes'"
     ]
    }
   ],
   "source": [
    "#ds = test_dataset(, , 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
