{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.face_recognition_test import Face_Fecognition_test\n",
    "from evaluation.ijb_evals import instantiate_list\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from hydra.utils import instantiate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images with lowest SCF unc and highest proposed unc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('/app/configs/uncertainty_benchmark/ijb_evals.yaml')\n",
    "method = cfg.open_set_identification_methods[0]\n",
    "sampler = instantiate(method.sampler)\n",
    "evaluation_function = instantiate(method.evaluation_function)\n",
    "assert evaluation_function is not None\n",
    "# if cfg.test_dataset.dataset_name == \"survFace\" and method.use_detector_score:\n",
    "#     continue\n",
    "template_pooling = instantiate(method.template_pooling_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_set_identification_metrics = instantiate_list(\n",
    "    cfg.open_set_identification_metrics\n",
    ")\n",
    "if \"open_set_uncertainty_metrics\" in cfg:\n",
    "    open_set_uncertainty_metrics = instantiate_list(\n",
    "        cfg.open_set_uncertainty_metrics\n",
    "    )\n",
    "else:\n",
    "    open_set_uncertainty_metrics = []\n",
    "closed_set_identification_metrics = instantiate_list(\n",
    "    cfg.closed_set_identification_metrics\n",
    ")\n",
    "verification_metrics = instantiate_list(cfg.verification_metrics)\n",
    "\n",
    "test_dataset = instantiate(cfg.test_dataset)\n",
    "\n",
    "verif_scores, verif_names = [], []\n",
    "open_set_ident_scores, open_set_ident_names = [], []\n",
    "closed_set_ident_scores, closed_set_ident_names = [], []\n",
    "\n",
    "open_set_ident_rejection_scores, open_set_ident_rejection_names = [], []\n",
    "\n",
    "# create result dirs:\n",
    "dataset_name = cfg.test_dataset.dataset_name\n",
    "open_set_identification_result_dir = (\n",
    "    Path(cfg.exp_dir) / dataset_name / \"open_set_identification\"\n",
    ")\n",
    "open_set_identification_result_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "closed_set_identification_result_dir = (\n",
    "    Path(cfg.exp_dir) / dataset_name / \"closed_set_identification\"\n",
    ")\n",
    "closed_set_identification_result_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "verification_result_dir = Path(cfg.exp_dir) / dataset_name / \"verification\"\n",
    "verification_result_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# create result tables place holders\n",
    "open_set_recognition_result_metrics = {}\n",
    "open_set_uncertainty_result_metrics = {}\n",
    "\n",
    "open_set_ident_pretty_names = {}\n",
    "closed_set_ident_pretty_names = {}\n",
    "verication_pretty_names = {}\n",
    "# define methods\n",
    "\n",
    "tt = Face_Fecognition_test(\n",
    "    sampler=sampler,\n",
    "    evaluation_function=evaluation_function,\n",
    "    test_dataset=test_dataset,\n",
    "    embeddings_path=method.embeddings_path,\n",
    "    template_pooling_strategy=template_pooling,\n",
    "    use_detector_score=method.use_detector_score,\n",
    "    use_two_galleries=cfg.use_two_galleries,\n",
    "    recompute_template_pooling=cfg.recompute_template_pooling,\n",
    "    open_set_identification_metrics=open_set_identification_metrics,\n",
    "    closed_set_identification_metrics=closed_set_identification_metrics,\n",
    "    verification_metrics=verification_metrics,\n",
    "    open_set_uncertainty_metrics=open_set_uncertainty_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    g1_templates_feature,\n",
    "    g1_template_unc,\n",
    "    g1_unique_ids,\n",
    ") = tt.get_template_subsets(\n",
    "    tt.test_dataset.g1_templates, tt.test_dataset.g1_ids\n",
    ")\n",
    "# print(\"g1_templates_feature:\", g1_templates_feature.shape)  # (1772, 512)\n",
    "\n",
    "(\n",
    "    probe_templates_feature,\n",
    "    probe_template_unc,\n",
    "    probe_unique_ids,\n",
    ") = tt.get_template_subsets(\n",
    "    tt.test_dataset.probe_templates, tt.test_dataset.probe_ids\n",
    ")\n",
    "\n",
    "# sample probe feature vectors\n",
    "\n",
    "probe_templates_feature = tt.sampler(\n",
    "    probe_templates_feature,\n",
    "    probe_template_unc,\n",
    ")\n",
    "\n",
    "similarity, probe_score = tt.evaluation_function(\n",
    "    probe_templates_feature,\n",
    "    probe_template_unc,\n",
    "    g1_templates_feature,\n",
    "    g1_template_unc,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_scores = {}\n",
    "for unc_metric in tt.open_set_uncertainty_metrics:\n",
    "    if hasattr(unc_metric, 'data_variance_weight') is False:\n",
    "        continue\n",
    "    if unc_metric.data_variance_weight == 0:\n",
    "        unc_scores[\"probe_unc\"] = unc_metric\n",
    "    elif unc_metric.data_variance_weight == 1:\n",
    "        unc_scores[\"scf_unc\"] = unc_metric\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_score = unc_scores[\"probe_unc\"](\n",
    "                    probe_ids=probe_unique_ids,\n",
    "                    probe_template_unc=probe_template_unc,\n",
    "                    gallery_ids=g1_unique_ids,\n",
    "                    similarity=similarity,\n",
    "                    probe_score=probe_score,\n",
    "                )[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scf_score = unc_scores[\"scf_unc\"](\n",
    "                    probe_ids=probe_unique_ids,\n",
    "                    probe_template_unc=probe_template_unc,\n",
    "                    gallery_ids=g1_unique_ids,\n",
    "                    similarity=similarity,\n",
    "                    probe_score=probe_score,\n",
    "                )[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_conf_ids = np.argsort(scf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_templates = np.unique(tt.test_dataset.probe_templates, return_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15883,  17099, 187475, ...,  21742, 179072,  16673])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_templates[most_conf_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.data_tools import read_meta_columns_to_int\n",
    "import pandas as pd\n",
    "data_path = Path(cfg.test_dataset.dataset_path)\n",
    "media_list_path = data_path / \"meta\" / f\"{dataset_name.lower()}_face_tid_mid.txt\"\n",
    "pair_list_path = (\n",
    "    data_path / \"meta\" / f\"{dataset_name.lower()}_template_pair_label.txt\"\n",
    ")\n",
    "img_path = data_path / \"loose_crop\"\n",
    "img_list_path = data_path / \"meta\" / f\"{dataset_name.lower()}_name_5pts_score.txt\"\n",
    "\n",
    "meta = pd.read_csv(media_list_path, sep=\" \", skiprows=0, header=None).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = meta[:, 0]\n",
    "template_ids = meta[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_templates = unique_templates[most_conf_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "test_foulder = Path('outputs/test_high_scf')\n",
    "test_foulder.mkdir(exist_ok=True)\n",
    "for template_id in sorted_templates[:10]:\n",
    "    test_template_path = test_foulder / str(template_id)\n",
    "    test_template_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # copy image\n",
    "    for image_name in image_paths[template_ids==template_id]:\n",
    "        in_image_name = data_path / 'loose_crop' / image_name\n",
    "        out_image_name = test_template_path / image_name\n",
    "        copyfile(in_image_name, out_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "test_foulder = Path('outputs/test_low_scf')\n",
    "test_foulder.mkdir(exist_ok=True)\n",
    "for template_id in sorted_templates[-10:]:\n",
    "    test_template_path = test_foulder / str(template_id)\n",
    "    test_template_path.mkdir(exist_ok=True)\n",
    "\n",
    "    # copy image\n",
    "    for image_name in image_paths[template_ids==template_id]:\n",
    "        in_image_name = data_path / 'loose_crop' / image_name\n",
    "        out_image_name = test_template_path / image_name\n",
    "        copyfile(in_image_name, out_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high scf low prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = similarity[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_template_images(data_path, test_template_path, template_id):\n",
    "    test_template_path.mkdir(exist_ok=True)\n",
    "    # copy template images\n",
    "    for image_name in image_paths[template_ids==template_id]:\n",
    "        in_image_name = data_path / 'loose_crop' / image_name\n",
    "        out_image_name = test_template_path / image_name\n",
    "        copyfile(in_image_name, out_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile, rmtree\n",
    "test_foulder = Path('outputs/test_high_scf_low_prob_neighbors_g1')\n",
    "in_galley_path = test_foulder / 'in_gallery_probe'\n",
    "out_of_galley_path = test_foulder / 'out_of_gallery_probe'\n",
    "rmtree(test_foulder, ignore_errors=True)\n",
    "test_foulder.mkdir(exist_ok=True)\n",
    "g1_unique_templates = np.unique(tt.test_dataset.g1_templates, return_index=False) \n",
    "scf_size = 500\n",
    "\n",
    "max_scf_prob_scores_ids = np.argsort(probe_score[most_conf_ids][:scf_size])[::-1]\n",
    "prob_score_template_ids = unique_templates[most_conf_ids][:scf_size][max_scf_prob_scores_ids]\n",
    "\n",
    "scf_conf = scf_score[most_conf_ids][:scf_size][max_scf_prob_scores_ids]\n",
    "probe_conf = probe_score[most_conf_ids][:scf_size][max_scf_prob_scores_ids]\n",
    "for i, probe_template_id in enumerate(prob_score_template_ids):\n",
    "    template_pos = np.where(unique_templates == probe_template_id)[0][0]\n",
    "    is_in_gallery = np.isin(probe_unique_ids[template_pos], g1_unique_ids)\n",
    "    most_similar_gallery_ids = np.argsort(similarity[template_pos,:])[::-1]\n",
    "    most_similar_templates = g1_unique_templates[most_similar_gallery_ids[:4]]\n",
    "    if is_in_gallery:\n",
    "        out_path = in_galley_path\n",
    "    else:\n",
    "        out_path = out_of_galley_path\n",
    "    if probe_conf[i] < 5.275974925543694e-13:\n",
    "        continue\n",
    "    probe_template_path = out_path / f\"probe_id: {str(probe_unique_ids[template_pos])}_scf-unc: {scf_conf[i]}_prob-unc: {probe_conf[i]}\"\n",
    "    probe_template_path.mkdir(exist_ok=True, parents=True)\n",
    "    copy_template_images(data_path, probe_template_path / 'probe_images', probe_template_id)\n",
    "    for j, template_id in enumerate(most_similar_templates):\n",
    "        cos_sim = similarity[template_pos,most_similar_gallery_ids[j]]\n",
    "        id = g1_unique_ids[most_similar_gallery_ids[j]]\n",
    "        test_template_path = probe_template_path / f\"close-gallery-id: {str(id)}_sim:{cos_sim}\"\n",
    "        test_template_path.mkdir(exist_ok=True, parents=True)\n",
    "        copy_template_images(data_path, test_template_path, template_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19593, 1772)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_gallery_ids[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
