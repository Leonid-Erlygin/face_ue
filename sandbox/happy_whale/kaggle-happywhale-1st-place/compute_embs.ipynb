{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import SphereClassifier, WhaleDataModule\n",
    "from src.dataset import load_df\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from config.config import Config, load_config\n",
    "\n",
    "cuda = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erlygin/miniconda/lib/python3.9/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b6_ns to current tf_efficientnet_b6.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dims: [200, 576]\n"
     ]
    }
   ],
   "source": [
    "model = SphereClassifier.load_from_checkpoint(\n",
    "    checkpoint_path=\"/app/sandbox/happy_whale/kaggle-happywhale-1st-place/result/b6_bottleneck_feature_fix_nb/1/last-v4.ckpt\"\n",
    ")\n",
    "model.to(cuda)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "image = torch.rand(1, 3, 528, 528).to(cuda)\n",
    "# logits_ids, logits_species = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "\n",
    "# image = torch.rand(1, 3, 528, 528).to(cuda)\n",
    "# yhat = model(image)\n",
    "# make_dot(yhat, params=dict(list(model.named_parameters()))).render(\n",
    "#     \"b6_torchviz\", \"b6.png\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute embs on train ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used default config lr_backbone: 0.0016\n",
      "used default config lr_head: 0.016\n",
      "used default config lr_decay_scale: 0.01\n",
      "used default config num_classes: 15587\n",
      "used default config num_species_classes: 26\n",
      "used default config pretrained: True\n",
      "used default config val_bbox: fullbody\n",
      "used default config test_bboxes: ['fullbody', 'fullbody_charm']\n",
      "used default config bboxes: {'fullbody_charm': 0.15, 'fullbody': 0.6, 'backfin': 0.15, 'detic': 0.05, 'none': 0.05}\n",
      "used default config bbox_conf_threshold: 0.01\n",
      "used default config n_data: -1\n",
      "used default config global_pool: {'arch': 'GeM', 'p': 3, 'train': False}\n",
      "used default config normalization: batchnorm\n",
      "used default config optimizer: AdamW\n",
      "used default config loss_fn: CrossEntropy\n",
      "used default config loss_id_ratio: 0.437338\n",
      "used default config margin_coef_id: 0.27126\n",
      "used default config margin_coef_species: 0.226253\n",
      "used default config margin_power_id: -0.364399\n",
      "used default config margin_power_species: -0.720133\n",
      "used default config s_id: 20.9588\n",
      "used default config s_species: 33.1383\n",
      "used default config margin_cons_id: 0.05\n",
      "used default config margin_cons_species: 0.05\n",
      "used default config n_center_id: 1\n",
      "used default config n_center_species: 1\n",
      "used default config aug: {'rotate': 15, 'translate': 0.25, 'shear': 3, 'p_affine': 0.5, 'crop_scale': 0.9, 'crop_l': 0.75, 'crop_r': 1.3333333333333333, 'p_gray': 0.1, 'p_blur': 0.05, 'p_noise': 0.05, 'p_downscale': 0.0, 'p_shuffle': 0.3, 'p_posterize': 0.2, 'p_bright_contrast': 0.5, 'p_cutout': 0.05, 'p_snow': 0.1, 'p_rain': 0.05}\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"config/efficientnet_b6_new.yaml\", \"config/default.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detic low conf: 0 / 51033\n",
      "fullbody low conf: 0 / 51033\n",
      "fullbody_charm low conf: 10 / 51033\n",
      "backfin low conf: 1587 / 51033\n"
     ]
    }
   ],
   "source": [
    "df = load_df(\"input\", cfg, \"train.csv\", True)\n",
    "data_module = WhaleDataModule(\n",
    "    df,\n",
    "    cfg,\n",
    "    f\"input/train_images\",\n",
    "    cfg.val_bbox,\n",
    "    -1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_module.get_dataset(df, False)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=32,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51033 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "model.eval()\n",
    "\n",
    "for batch in tqdm(train_loader):\n",
    "    images = batch[\"image\"].to(cuda)\n",
    "    out = model(images)\n",
    "    bottleneck_feat = model.get_bottleneck_feature(images)\n",
    "    feats = model.backbone_head_bn(model.backbone_head(bottleneck_feat))\n",
    "    feats = F.normalize(feats, p=2.0, dim=1)\n",
    "    predictions.append(feats.detach().cpu())\n",
    "    break\n",
    "# embs = torch.cat(predictions, axis=0).numpy()\n",
    "# np.savez(f\"whale_train_emb.npz\", embs=embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8775, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[-0.1212, -0.0834, -0.0605, -0.0542, -0.0526, -0.0472, -0.0452, -0.0428,\n",
       "         -0.0411, -0.0383, -0.0352, -0.0264, -0.0155, -0.0129, -0.0079, -0.0074,\n",
       "         -0.0020, -0.0015,  0.0007,  0.0040,  0.0047,  0.0227,  0.0235,  0.0411,\n",
       "          0.0523,  0.3252]], device='cuda:0', grad_fn=<SortBackward0>),\n",
       "indices=tensor([[24, 19, 16,  2,  7, 18, 11, 25,  0,  9,  5, 23, 22, 12, 10, 14,  3, 13,\n",
       "          4, 20,  8,  1, 17,  6, 21, 15]], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Whale Train OSFR protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.ids  # defines unique id of image. id \\in [0, 15587)\n",
    "a = np.load(\"whale_train_emb.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(f\"whale_train_emb.npz\", **a, unc=np.ones((a[\"embs\"].shape[0], 1)) * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.x_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids, count_ids = np.unique(train_dataset.ids, return_counts=True)\n",
    "\n",
    "out_of_gallery_ids = unique_ids[count_ids == 1]  # single image ids\n",
    "in_gallery_ids = unique_ids[count_ids > 1]\n",
    "assert len(out_of_gallery_ids) + len(in_gallery_ids) == 15587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_dataset.x_paths).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# construct gallery and probe temlates\n",
    "image_path_to_template_id = {}\n",
    "image_path_to_subject_id = {}\n",
    "\n",
    "gallery_templates = []\n",
    "known_probe_templates = []\n",
    "subject_id = 0\n",
    "gallery_template_id = 0\n",
    "probe_template_id = 10000\n",
    "for subject in in_gallery_ids:\n",
    "    subject_images_paths = train_dataset.x_paths[train_dataset.ids == subject]\n",
    "    image_count = len(subject_images_paths)\n",
    "    for i, image_path in enumerate(subject_images_paths):\n",
    "        image_path_to_subject_id[image_path] = subject_id\n",
    "        if i < image_count // 2:\n",
    "            image_path_to_template_id[image_path] = gallery_template_id\n",
    "        if i >= image_count // 2:\n",
    "            image_path_to_template_id[image_path] = probe_template_id\n",
    "\n",
    "    gallery_templates.append(\n",
    "        (subject_images_paths[: image_count // 2], gallery_template_id, subject_id)\n",
    "    )\n",
    "    known_probe_templates.append(\n",
    "        (subject_images_paths[image_count // 2 :], probe_template_id, subject_id)\n",
    "    )\n",
    "    gallery_template_id += 1\n",
    "    probe_template_id += 1\n",
    "    subject_id += 1\n",
    "\n",
    "assert gallery_template_id < 10000\n",
    "unknown_probe_templates = []\n",
    "\n",
    "for probe_subject in out_of_gallery_ids:\n",
    "    probe_images_paths = train_dataset.x_paths[train_dataset.ids == probe_subject]\n",
    "    for image_path in probe_images_paths:\n",
    "        image_path = str(image_path)\n",
    "        image_path_to_subject_id[image_path] = subject_id\n",
    "        image_path_to_template_id[image_path] = probe_template_id\n",
    "    unknown_probe_templates.append((probe_images_paths, probe_template_id, subject_id))\n",
    "    probe_template_id += 1\n",
    "    subject_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(image_path_to_template_id) == len(train_dataset.x_paths)\n",
    "assert len(image_path_to_subject_id) == len(train_dataset.x_paths)\n",
    "assert len(set(image_path_to_subject_id.values())) == len(unique_ids)\n",
    "assert len(set(image_path_to_template_id.values())) == len(unique_ids) + len(\n",
    "    in_gallery_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gallery_templates), len(known_probe_templates), len(unknown_probe_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unknown_probe_templates) / (\n",
    "    len(known_probe_templates) + len(unknown_probe_templates)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(known_probe_templates) + len(unknown_probe_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds_name = \"whale\"\n",
    "# create meta files\n",
    "# tid mid\n",
    "identification_ds_path = Path(\"/app/datasets/whale_train\")\n",
    "identification_ds_path.mkdir(exist_ok=True)\n",
    "meta_path = identification_ds_path / \"meta\"\n",
    "meta_path.mkdir(exist_ok=True)\n",
    "img_names = train_dataset.x_paths\n",
    "# names = [x.split(\"/\")[-1] for x in img_names]\n",
    "names = img_names\n",
    "mids = np.arange(len(img_names))\n",
    "tids = []\n",
    "sids = []\n",
    "\n",
    "for image_path in img_names:\n",
    "    tids.append(image_path_to_template_id[image_path])\n",
    "    sids.append(image_path_to_subject_id[image_path])\n",
    "\n",
    "out_file_tid_mid = meta_path / Path(f\"{ds_name}_face_tid_mid.txt\")\n",
    "with open(out_file_tid_mid, \"w\") as fd:\n",
    "    for name, tid, sid, mid in zip(names, tids, sids, mids):\n",
    "        fd.write(f\"{name} {tid} {mid} {sid}\\n\")\n",
    "\n",
    "out_file_probe = meta_path / Path(f\"{ds_name}_1N_probe_mixed.csv\")\n",
    "out_file_gallery = meta_path / Path(f\"{ds_name}_1N_gallery_G1.csv\")\n",
    "\n",
    "tids_probe = []\n",
    "sids_probe = []\n",
    "names_probe = []\n",
    "for probe_meta in known_probe_templates + unknown_probe_templates:\n",
    "    tids_probe.extend([probe_meta[1]] * len(probe_meta[0]))\n",
    "    sids_probe.extend([probe_meta[2]] * len(probe_meta[0]))\n",
    "    names_probe.extend([x.split(\"/\")[-1] for x in probe_meta[0]])\n",
    "\n",
    "tids_gallery = []\n",
    "sids_gallery = []\n",
    "names_gallery = []\n",
    "\n",
    "for gallery_meta in gallery_templates:\n",
    "    tids_gallery.extend([gallery_meta[1]] * len(gallery_meta[0]))\n",
    "    sids_gallery.extend([gallery_meta[2]] * len(gallery_meta[0]))\n",
    "    names_gallery.extend([x.split(\"/\")[-1] for x in gallery_meta[0]])\n",
    "\n",
    "assert len(tids_gallery) + len(tids_probe) == len(img_names)\n",
    "probe = pd.DataFrame(\n",
    "    {\n",
    "        \"TEMPLATE_ID\": tids_probe,\n",
    "        \"SUBJECT_ID\": sids_probe,\n",
    "        \"FILENAME\": names_probe,\n",
    "    }\n",
    ")\n",
    "gallery = pd.DataFrame(\n",
    "    {\n",
    "        \"TEMPLATE_ID\": tids_gallery,\n",
    "        \"SUBJECT_ID\": sids_gallery,\n",
    "        \"FILENAME\": names_gallery,\n",
    "    }\n",
    ")\n",
    "\n",
    "probe.to_csv(out_file_probe, sep=\",\", index=False)\n",
    "gallery.to_csv(out_file_gallery, sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = identification_ds_path / \"embeddings\"\n",
    "emb_dir.mkdir(exist_ok=True)\n",
    "np.savez(emb_dir / \"b6_embs_whale.npz\", **a, unc=np.ones((a[\"embs\"].shape[0], 1)) * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((a[\"embs\"].shape[0], 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
