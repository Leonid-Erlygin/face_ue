{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import SphereClassifier, WhaleDataModule\n",
    "from src.dataset import load_df\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from config.config import Config, load_config\n",
    "\n",
    "cuda = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SphereClassifier.load_from_checkpoint(\n",
    "#     checkpoint_path=\"/app/sandbox/happy_whale/kaggle-happywhale-1st-place/result/b6_new/1/last.ckpt\"\n",
    "# )\n",
    "# model.to(cuda)\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# image = torch.rand(1, 3, 528, 528).to(cuda)\n",
    "# logits_ids, logits_species = model(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute embs on train ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used default config lr_backbone: 0.0016\n",
      "used default config lr_head: 0.016\n",
      "used default config lr_decay_scale: 0.01\n",
      "used default config num_classes: 15587\n",
      "used default config num_species_classes: 26\n",
      "used default config pretrained: True\n",
      "used default config val_bbox: fullbody\n",
      "used default config test_bboxes: ['fullbody', 'fullbody_charm']\n",
      "used default config bboxes: {'fullbody_charm': 0.15, 'fullbody': 0.6, 'backfin': 0.15, 'detic': 0.05, 'none': 0.05}\n",
      "used default config bbox_conf_threshold: 0.01\n",
      "used default config n_data: -1\n",
      "used default config global_pool: {'arch': 'GeM', 'p': 3, 'train': False}\n",
      "used default config normalization: batchnorm\n",
      "used default config optimizer: AdamW\n",
      "used default config loss_fn: CrossEntropy\n",
      "used default config loss_id_ratio: 0.437338\n",
      "used default config margin_coef_id: 0.27126\n",
      "used default config margin_coef_species: 0.226253\n",
      "used default config margin_power_id: -0.364399\n",
      "used default config margin_power_species: -0.720133\n",
      "used default config s_id: 20.9588\n",
      "used default config s_species: 33.1383\n",
      "used default config margin_cons_id: 0.05\n",
      "used default config margin_cons_species: 0.05\n",
      "used default config n_center_id: 1\n",
      "used default config n_center_species: 1\n",
      "used default config aug: {'rotate': 15, 'translate': 0.25, 'shear': 3, 'p_affine': 0.5, 'crop_scale': 0.9, 'crop_l': 0.75, 'crop_r': 1.3333333333333333, 'p_gray': 0.1, 'p_blur': 0.05, 'p_noise': 0.05, 'p_downscale': 0.0, 'p_shuffle': 0.3, 'p_posterize': 0.2, 'p_bright_contrast': 0.5, 'p_cutout': 0.05, 'p_snow': 0.1, 'p_rain': 0.05}\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"config/efficientnet_b6_new.yaml\", \"config/default.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detic low conf: 0 / 51033\n",
      "fullbody low conf: 0 / 51033\n",
      "fullbody_charm low conf: 10 / 51033\n",
      "backfin low conf: 1587 / 51033\n"
     ]
    }
   ],
   "source": [
    "df = load_df(\"input\", cfg, \"train.csv\", True)\n",
    "data_module = WhaleDataModule(\n",
    "    df,\n",
    "    cfg,\n",
    "    f\"input/train_images\",\n",
    "    cfg.val_bbox,\n",
    "    -1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_module.get_dataset(df, False)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=32,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# model.eval()\n",
    "\n",
    "# for batch in tqdm(train_loader):\n",
    "#     images = batch['image'].to(cuda)\n",
    "#     feats = F.normalize(model.get_feat(images), p=2.0, dim=1)\n",
    "#     predictions.append(feats.detach().cpu())\n",
    "# embs = torch.cat(predictions, axis=0).numpy()\n",
    "# #np.savez(f\"whale_train_emb.npz\", embs=embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Whale Train OSFR protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.ids  # defines unique id of image. id \\in [0, 15587)\n",
    "a = np.load(\"whale_train_emb.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00021adfb725ed.jpg', '000562241d384d.jpg', '0007c33415ce37.jpg',\n",
       "       ..., 'fff94675cc1aef.jpg', 'fffbc5dd642d8c.jpg',\n",
       "       'fffdcd42312777.jpg'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.x_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51033, 776)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"embs\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids, count_ids = np.unique(train_dataset.ids, return_counts=True)\n",
    "\n",
    "out_of_gallery_ids = unique_ids[count_ids == 1]  # single image ids\n",
    "in_gallery_ids = unique_ids[count_ids > 1]\n",
    "assert len(out_of_gallery_ids) + len(in_gallery_ids) == 15587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51033,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_dataset.x_paths).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# construct gallery and probe temlates\n",
    "image_path_to_template_id = {}\n",
    "image_path_to_subject_id = {}\n",
    "\n",
    "gallery_templates = []\n",
    "known_probe_templates = []\n",
    "subject_id = 0\n",
    "gallery_template_id = 0\n",
    "probe_template_id = 10000\n",
    "for subject in in_gallery_ids:\n",
    "    subject_images_paths = train_dataset.x_paths[train_dataset.ids == subject]\n",
    "    image_count = len(subject_images_paths)\n",
    "    for i, image_path in enumerate(subject_images_paths):\n",
    "        image_path_to_subject_id[image_path] = subject_id\n",
    "        if i < image_count // 2:\n",
    "            image_path_to_template_id[image_path] = gallery_template_id\n",
    "        if i >= image_count // 2:\n",
    "            image_path_to_template_id[image_path] = probe_template_id\n",
    "\n",
    "    gallery_templates.append(\n",
    "        (subject_images_paths[: image_count // 2], gallery_template_id, subject_id)\n",
    "    )\n",
    "    known_probe_templates.append(\n",
    "        (subject_images_paths[image_count // 2 :], probe_template_id, subject_id)\n",
    "    )\n",
    "    gallery_template_id += 1\n",
    "    probe_template_id += 1\n",
    "    subject_id += 1\n",
    "\n",
    "assert gallery_template_id < 10000\n",
    "unknown_probe_templates = []\n",
    "\n",
    "for probe_subject in out_of_gallery_ids:\n",
    "    probe_images_paths = train_dataset.x_paths[train_dataset.ids == probe_subject]\n",
    "    for image_path in probe_images_paths:\n",
    "        image_path = str(image_path)\n",
    "        image_path_to_subject_id[image_path] = subject_id\n",
    "        image_path_to_template_id[image_path] = probe_template_id\n",
    "    unknown_probe_templates.append((probe_images_paths, probe_template_id, subject_id))\n",
    "    probe_template_id += 1\n",
    "    subject_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(image_path_to_template_id) == len(train_dataset.x_paths)\n",
    "assert len(image_path_to_subject_id) == len(train_dataset.x_paths)\n",
    "assert len(set(image_path_to_subject_id.values())) == len(unique_ids)\n",
    "assert len(set(image_path_to_template_id.values())) == len(unique_ids) + len(\n",
    "    in_gallery_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6329, 6329, 9258)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gallery_templates), len(known_probe_templates), len(unknown_probe_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5939565022133829"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unknown_probe_templates) / (\n",
    "    len(known_probe_templates) + len(unknown_probe_templates)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15587"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known_probe_templates) + len(unknown_probe_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds_name = \"whale\"\n",
    "# create meta files\n",
    "# tid mid\n",
    "identification_ds_path = Path(\"/app/datasets/whale_train\")\n",
    "identification_ds_path.mkdir(exist_ok=True)\n",
    "meta_path = identification_ds_path / \"meta\"\n",
    "meta_path.mkdir(exist_ok=True)\n",
    "img_names = train_dataset.x_paths\n",
    "# names = [x.split(\"/\")[-1] for x in img_names]\n",
    "names = img_names\n",
    "mids = np.arange(len(img_names))\n",
    "tids = []\n",
    "sids = []\n",
    "\n",
    "for image_path in img_names:\n",
    "    tids.append(image_path_to_template_id[image_path])\n",
    "    sids.append(image_path_to_subject_id[image_path])\n",
    "\n",
    "out_file_tid_mid = meta_path / Path(f\"{ds_name}_face_tid_mid.txt\")\n",
    "with open(out_file_tid_mid, \"w\") as fd:\n",
    "    for name, tid, sid, mid in zip(names, tids, sids, mids):\n",
    "        fd.write(f\"{name} {tid} {mid} {sid}\\n\")\n",
    "\n",
    "out_file_probe = meta_path / Path(f\"{ds_name}_1N_probe_mixed.csv\")\n",
    "out_file_gallery = meta_path / Path(f\"{ds_name}_1N_gallery_G1.csv\")\n",
    "\n",
    "tids_probe = []\n",
    "sids_probe = []\n",
    "names_probe = []\n",
    "for probe_meta in known_probe_templates + unknown_probe_templates:\n",
    "    tids_probe.extend([probe_meta[1]] * len(probe_meta[0]))\n",
    "    sids_probe.extend([probe_meta[2]] * len(probe_meta[0]))\n",
    "    names_probe.extend([x.split(\"/\")[-1] for x in probe_meta[0]])\n",
    "\n",
    "tids_gallery = []\n",
    "sids_gallery = []\n",
    "names_gallery = []\n",
    "\n",
    "for gallery_meta in gallery_templates:\n",
    "    tids_gallery.extend([gallery_meta[1]] * len(gallery_meta[0]))\n",
    "    sids_gallery.extend([gallery_meta[2]] * len(gallery_meta[0]))\n",
    "    names_gallery.extend([x.split(\"/\")[-1] for x in gallery_meta[0]])\n",
    "\n",
    "assert len(tids_gallery) + len(tids_probe) == len(img_names)\n",
    "probe = pd.DataFrame(\n",
    "    {\n",
    "        \"TEMPLATE_ID\": tids_probe,\n",
    "        \"SUBJECT_ID\": sids_probe,\n",
    "        \"FILENAME\": names_probe,\n",
    "    }\n",
    ")\n",
    "gallery = pd.DataFrame(\n",
    "    {\n",
    "        \"TEMPLATE_ID\": tids_gallery,\n",
    "        \"SUBJECT_ID\": sids_gallery,\n",
    "        \"FILENAME\": names_gallery,\n",
    "    }\n",
    ")\n",
    "\n",
    "probe.to_csv(out_file_probe, sep=\",\", index=False)\n",
    "gallery.to_csv(out_file_gallery, sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = identification_ds_path / \"embeddings\"\n",
    "emb_dir.mkdir(exist_ok=True)\n",
    "np.savez(emb_dir / \"b6_embs_whale.npz\", **a, unc=np.ones((a[\"embs\"].shape[0], 1)) * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51033, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((a[\"embs\"].shape[0], 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
