{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import SphereClassifier, WhaleDataModule\n",
    "from src.dataset import load_df\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from config.config import Config, load_config\n",
    "\n",
    "# cuda = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SphereClassifier.load_from_checkpoint(\n",
    "#     checkpoint_path=\"/app/sandbox/happy_whale/kaggle-happywhale-1st-place/result/b6_bottleneck_feature_fix_nb/1/last-v4.ckpt\"\n",
    "# )\n",
    "# model.to(cuda)\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# image = torch.rand(1, 3, 528, 528).to(cuda)\n",
    "# logits_ids, logits_species = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "\n",
    "# image = torch.rand(1, 3, 528, 528).to(cuda)\n",
    "# yhat = model(image)\n",
    "# make_dot(yhat, params=dict(list(model.named_parameters()))).render(\n",
    "#     \"b6_torchviz\", \"b6.png\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute embs on train ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used default config lr_backbone: 0.0016\n",
      "used default config lr_head: 0.016\n",
      "used default config lr_decay_scale: 0.01\n",
      "used default config num_classes: 15587\n",
      "used default config num_species_classes: 26\n",
      "used default config pretrained: True\n",
      "used default config val_bbox: fullbody\n",
      "used default config test_bboxes: ['fullbody', 'fullbody_charm']\n",
      "used default config bboxes: {'fullbody_charm': 0.15, 'fullbody': 0.6, 'backfin': 0.15, 'detic': 0.05, 'none': 0.05}\n",
      "used default config bbox_conf_threshold: 0.01\n",
      "used default config n_data: -1\n",
      "used default config global_pool: {'arch': 'GeM', 'p': 3, 'train': False}\n",
      "used default config normalization: batchnorm\n",
      "used default config optimizer: AdamW\n",
      "used default config loss_fn: CrossEntropy\n",
      "used default config loss_id_ratio: 0.437338\n",
      "used default config margin_coef_id: 0.27126\n",
      "used default config margin_coef_species: 0.226253\n",
      "used default config margin_power_id: -0.364399\n",
      "used default config margin_power_species: -0.720133\n",
      "used default config s_id: 20.9588\n",
      "used default config s_species: 33.1383\n",
      "used default config margin_cons_id: 0.05\n",
      "used default config margin_cons_species: 0.05\n",
      "used default config n_center_id: 1\n",
      "used default config n_center_species: 1\n",
      "used default config aug: {'rotate': 15, 'translate': 0.25, 'shear': 3, 'p_affine': 0.5, 'crop_scale': 0.9, 'crop_l': 0.75, 'crop_r': 1.3333333333333333, 'p_gray': 0.1, 'p_blur': 0.05, 'p_noise': 0.05, 'p_downscale': 0.0, 'p_shuffle': 0.3, 'p_posterize': 0.2, 'p_bright_contrast': 0.5, 'p_cutout': 0.05, 'p_snow': 0.1, 'p_rain': 0.05}\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"config/efficientnet_b6_new.yaml\", \"config/default.yaml\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detic low conf: 0 / 51033\n",
      "fullbody low conf: 0 / 51033\n",
      "fullbody_charm low conf: 10 / 51033\n",
      "backfin low conf: 1587 / 51033\n"
     ]
    }
   ],
   "source": [
    "df = load_df(\"input\", cfg, \"train.csv\", True)\n",
    "data_module = WhaleDataModule(\n",
    "    df,\n",
    "    cfg,\n",
    "    f\"input/train_images\",\n",
    "    cfg.val_bbox,\n",
    "    -1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_module.get_dataset(df, False)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=32,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# model.eval()\n",
    "\n",
    "# for batch in tqdm(train_loader):\n",
    "#     images = batch[\"image\"].to(cuda)\n",
    "#     out = model(images)\n",
    "#     bottleneck_feat = model.get_bottleneck_feature(images)\n",
    "#     feats = model.backbone_head_bn(model.backbone_head(bottleneck_feat))\n",
    "#     feats = F.normalize(feats, p=2.0, dim=1)\n",
    "#     predictions.append(feats.detach().cpu())\n",
    "#     break\n",
    "# embs = torch.cat(predictions, axis=0).numpy()\n",
    "# np.savez(f\"whale_train_emb.npz\", embs=embs)\n",
    "# out[0].max(), out[1].sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Whale Train OSFR protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check scf embs\n",
    "# a = np.load(\"whale_train_emb.npz\")\n",
    "# b = np.load(\"/app/cache/features/scf_embs_whale.npz\")\n",
    "# a[\"embs\"], b[\"embs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create whale validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set_id_num = 5000\n",
    "rng = np.random.default_rng(1)\n",
    "\n",
    "unique_ids, count_ids = np.unique(train_dataset.ids, return_counts=True)\n",
    "validation_id_idx = rng.choice(\n",
    "    unique_ids.shape[0], validation_set_id_num, replace=False\n",
    ")\n",
    "test_id_idx = np.array(\n",
    "    sorted(list(set(range(unique_ids.shape[0])) - set(validation_id_idx)))\n",
    ")\n",
    "assert validation_id_idx.shape[0] + test_id_idx.shape[0] == unique_ids.shape[0]\n",
    "assert set(validation_id_idx).intersection(test_id_idx) == set()\n",
    "\n",
    "validation_unique_ids, validation_count_ids = (\n",
    "    unique_ids[validation_id_idx],\n",
    "    count_ids[validation_id_idx],\n",
    ")\n",
    "test_unique_ids, test_count_ids = unique_ids[test_id_idx], count_ids[test_id_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_whale_dataset(train_dataset, unique_ids, count_ids, full_ds_embs, ds_name):\n",
    "\n",
    "    out_of_gallery_ids = unique_ids[count_ids == 1]  # single image ids\n",
    "    print(f\"OOG id count: {len(out_of_gallery_ids)}\")\n",
    "    in_gallery_ids = unique_ids[count_ids > 1]\n",
    "    print(f\"In gallery id count: {len(in_gallery_ids)}\")\n",
    "    print(out_of_gallery_ids.shape, in_gallery_ids.shape)\n",
    "\n",
    "    # construct gallery and probe temlates\n",
    "    image_path_to_template_id = {}\n",
    "    image_path_to_subject_id = {}\n",
    "    image_path_to_emb = {}\n",
    "    image_path_to_unc = {}\n",
    "\n",
    "    # select embeddings\n",
    "    img_names = []  # train_dataset.x_paths\n",
    "    for subject in tqdm(unique_ids):\n",
    "        local_idx = train_dataset.ids == subject\n",
    "        subject_images_paths = train_dataset.x_paths[local_idx]\n",
    "        subject_embs = full_ds_embs[\"embs\"][local_idx]\n",
    "        subject_unc = full_ds_embs[\"unc\"][local_idx]\n",
    "        for image_path, emb, unc in zip(\n",
    "            subject_images_paths, subject_embs, subject_unc\n",
    "        ):\n",
    "            img_names.append(image_path)\n",
    "            image_path_to_emb[image_path] = emb[np.newaxis, :]\n",
    "            image_path_to_unc[image_path] = unc[np.newaxis, :]\n",
    "\n",
    "    gallery_templates = []\n",
    "    known_probe_templates = []\n",
    "\n",
    "    subject_id = 0\n",
    "    gallery_template_id = 0\n",
    "    probe_template_id = 10000\n",
    "    for subject in tqdm(in_gallery_ids):\n",
    "        subject_images_paths = train_dataset.x_paths[train_dataset.ids == subject]\n",
    "\n",
    "        image_count = len(subject_images_paths)\n",
    "        for i, image_path in enumerate(subject_images_paths):\n",
    "            image_path_to_subject_id[image_path] = subject_id\n",
    "            if i < image_count // 2:\n",
    "                image_path_to_template_id[image_path] = gallery_template_id\n",
    "            if i >= image_count // 2:\n",
    "                image_path_to_template_id[image_path] = probe_template_id\n",
    "\n",
    "        gallery_templates.append(\n",
    "            (subject_images_paths[: image_count // 2], gallery_template_id, subject_id)\n",
    "        )\n",
    "        known_probe_templates.append(\n",
    "            (subject_images_paths[image_count // 2 :], probe_template_id, subject_id)\n",
    "        )\n",
    "        gallery_template_id += 1\n",
    "        probe_template_id += 1\n",
    "        subject_id += 1\n",
    "\n",
    "    assert gallery_template_id < 10000\n",
    "    unknown_probe_templates = []\n",
    "\n",
    "    for probe_subject in tqdm(out_of_gallery_ids):\n",
    "        probe_images_paths = train_dataset.x_paths[train_dataset.ids == probe_subject]\n",
    "        for image_path in probe_images_paths:\n",
    "            image_path = str(image_path)\n",
    "            image_path_to_subject_id[image_path] = subject_id\n",
    "            image_path_to_template_id[image_path] = probe_template_id\n",
    "        unknown_probe_templates.append(\n",
    "            (probe_images_paths, probe_template_id, subject_id)\n",
    "        )\n",
    "        probe_template_id += 1\n",
    "        subject_id += 1\n",
    "\n",
    "    # assert len(image_path_to_template_id) == len(train_dataset.x_paths)\n",
    "    # assert len(image_path_to_subject_id) == len(train_dataset.x_paths)\n",
    "    assert len(set(image_path_to_subject_id.values())) == len(unique_ids)\n",
    "    assert len(set(image_path_to_template_id.values())) == len(unique_ids) + len(\n",
    "        in_gallery_ids\n",
    "    )\n",
    "    print(\n",
    "        len(gallery_templates), len(known_probe_templates), len(unknown_probe_templates)\n",
    "    )\n",
    "    print(\n",
    "        len(unknown_probe_templates)\n",
    "        / (len(known_probe_templates) + len(unknown_probe_templates))\n",
    "    )\n",
    "    print(len(known_probe_templates) + len(unknown_probe_templates))\n",
    "\n",
    "    # create meta files\n",
    "    # tid mid\n",
    "    identification_ds_path = Path(f\"/app/datasets/{ds_name}\")\n",
    "    identification_ds_path.mkdir(exist_ok=True)\n",
    "    meta_path = identification_ds_path / \"meta\"\n",
    "    embeddings_path = identification_ds_path / \"embeddings\"\n",
    "    embeddings_path.mkdir(exist_ok=True)\n",
    "    meta_path.mkdir(exist_ok=True)\n",
    "\n",
    "    mids = np.arange(len(img_names))\n",
    "    tids = []\n",
    "    sids = []\n",
    "\n",
    "    for image_path in img_names:\n",
    "        tids.append(image_path_to_template_id[image_path])\n",
    "        sids.append(image_path_to_subject_id[image_path])\n",
    "\n",
    "    out_file_tid_mid = meta_path / Path(f\"{ds_name}_face_tid_mid.txt\")\n",
    "    with open(out_file_tid_mid, \"w\") as fd:\n",
    "        for name, tid, sid, mid in zip(img_names, tids, sids, mids):\n",
    "            fd.write(f\"{name} {tid} {mid} {sid}\\n\")\n",
    "\n",
    "    out_file_probe = meta_path / Path(f\"{ds_name}_1N_probe_mixed.csv\")\n",
    "    out_file_gallery = meta_path / Path(f\"{ds_name}_1N_gallery_G1.csv\")\n",
    "\n",
    "    tids_probe = []\n",
    "    sids_probe = []\n",
    "    names_probe = []\n",
    "    for probe_meta in known_probe_templates + unknown_probe_templates:\n",
    "        tids_probe.extend([probe_meta[1]] * len(probe_meta[0]))\n",
    "        sids_probe.extend([probe_meta[2]] * len(probe_meta[0]))\n",
    "        names_probe.extend([x.split(\"/\")[-1] for x in probe_meta[0]])\n",
    "\n",
    "    tids_gallery = []\n",
    "    sids_gallery = []\n",
    "    names_gallery = []\n",
    "\n",
    "    for gallery_meta in gallery_templates:\n",
    "        tids_gallery.extend([gallery_meta[1]] * len(gallery_meta[0]))\n",
    "        sids_gallery.extend([gallery_meta[2]] * len(gallery_meta[0]))\n",
    "        names_gallery.extend([x.split(\"/\")[-1] for x in gallery_meta[0]])\n",
    "\n",
    "    assert len(tids_gallery) + len(tids_probe) == len(img_names)\n",
    "    probe = pd.DataFrame(\n",
    "        {\n",
    "            \"TEMPLATE_ID\": tids_probe,\n",
    "            \"SUBJECT_ID\": sids_probe,\n",
    "            \"FILENAME\": names_probe,\n",
    "        }\n",
    "    )\n",
    "    gallery = pd.DataFrame(\n",
    "        {\n",
    "            \"TEMPLATE_ID\": tids_gallery,\n",
    "            \"SUBJECT_ID\": sids_gallery,\n",
    "            \"FILENAME\": names_gallery,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    probe.to_csv(out_file_probe, sep=\",\", index=False)\n",
    "    gallery.to_csv(out_file_gallery, sep=\",\", index=False)\n",
    "\n",
    "    # save embedding\n",
    "    embs = []\n",
    "    uncs = []\n",
    "    for image_name in image_path_to_emb.keys():\n",
    "        embs.append(image_path_to_emb[image_name])\n",
    "        uncs.append(image_path_to_unc[image_name])\n",
    "    embs = np.concatenate(embs, axis=0)\n",
    "    uncs = np.concatenate(uncs, axis=0)\n",
    "    print(embs.shape, uncs.shape)\n",
    "    # np.savez(embeddings_path / f\"scf_embs_{ds_name}.npz\", embs=embs, unc=uncs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<04:24, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOG id count: 2985\n",
      "In gallery id count: 2015\n",
      "(2985,) (2015,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 123/5000 [00:06<04:06, 19.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m full_ds_embs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/app/cache/features/scf_embs_whale.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcreate_whale_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_unique_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_count_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_ds_embs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhale_val\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mcreate_whale_dataset\u001b[0;34m(train_dataset, unique_ids, count_ids, full_ds_embs, ds_name)\u001b[0m\n\u001b[1;32m     21\u001b[0m local_idx \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mids \u001b[38;5;241m==\u001b[39m subject\n\u001b[1;32m     22\u001b[0m subject_images_paths \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mx_paths[local_idx]\n\u001b[0;32m---> 23\u001b[0m subject_embs \u001b[38;5;241m=\u001b[39m \u001b[43mfull_ds_embs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[local_idx]\n\u001b[1;32m     24\u001b[0m subject_unc \u001b[38;5;241m=\u001b[39m full_ds_embs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munc\u001b[39m\u001b[38;5;124m\"\u001b[39m][local_idx]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path, emb, unc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     26\u001b[0m     subject_images_paths, subject_embs, subject_unc\n\u001b[1;32m     27\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/numpy/lib/npyio.py:253\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/numpy/lib/format.py:763\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[1;32m    762\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[0;32m--> 763\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    764\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    765\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/numpy/lib/format.py:892\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 892\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m    894\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/zipfile.py:922\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 922\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    924\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/zipfile.py:1012\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_crc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/zipfile.py:937\u001b[0m, in \u001b[0;36mZipExtFile._update_crc\u001b[0;34m(self, newdata)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;66;03m# No need to compute the CRC if we don't have a reference value\u001b[39;00m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m=\u001b[39m \u001b[43mcrc32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_running_crc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Check the CRC if we're at the end of the file\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_crc \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expected_crc:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_ds_embs = np.load(\"/app/cache/features/scf_embs_whale.npz\")\n",
    "create_whale_dataset(\n",
    "    train_dataset,\n",
    "    validation_unique_ids,\n",
    "    validation_count_ids,\n",
    "    full_ds_embs,\n",
    "    \"whale_val\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/10587 [00:00<08:56, 19.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOG id count: 6273\n",
      "In gallery id count: 4314\n",
      "(6273,) (4314,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 76/10587 [00:03<09:00, 19.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_whale_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_unique_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_count_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_ds_embs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m, in \u001b[0;36mcreate_whale_dataset\u001b[0;34m(train_dataset, unique_ids, count_ids, full_ds_embs, ds_name)\u001b[0m\n\u001b[1;32m     21\u001b[0m local_idx \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mids \u001b[38;5;241m==\u001b[39m subject\n\u001b[1;32m     22\u001b[0m subject_images_paths \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mx_paths[local_idx]\n\u001b[0;32m---> 23\u001b[0m subject_embs \u001b[38;5;241m=\u001b[39m \u001b[43mfull_ds_embs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[local_idx]\n\u001b[1;32m     24\u001b[0m subject_unc \u001b[38;5;241m=\u001b[39m full_ds_embs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munc\u001b[39m\u001b[38;5;124m\"\u001b[39m][local_idx]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path, emb, unc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     26\u001b[0m     subject_images_paths, subject_embs, subject_unc\n\u001b[1;32m     27\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/numpy/lib/npyio.py:253\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/numpy/lib/format.py:763\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[1;32m    762\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[0;32m--> 763\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    764\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    765\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/numpy/lib/format.py:892\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 892\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m    894\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/zipfile.py:922\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 922\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    924\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/zipfile.py:992\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    990\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read2(n \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(data))\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 992\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_STORED:\n\u001b[1;32m    995\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/zipfile.py:1022\u001b[0m, in \u001b[0;36mZipExtFile._read2\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1019\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[1;32m   1020\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left)\n\u001b[0;32m-> 1022\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fileobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/zipfile.py:742\u001b[0m, in \u001b[0;36m_SharedFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt read from the ZIP file while there \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    739\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis an open writing handle on it. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    740\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose the writing handle before trying to read.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos)\n\u001b[0;32m--> 742\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mtell()\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "create_whale_dataset(\n",
    "    train_dataset, test_unique_ids, test_count_ids, full_ds_embs, \"whale\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.62920386, -0.009191476)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load(\"/app/datasets/whale_val/embeddings/scf_embs_whale.npz\")\n",
    "a[\"embs\"][0] @ a[\"embs\"][1], a[\"embs\"][0] @ a[\"embs\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80075425, 0.8756635, 0.8109231, 0.709551, 0.12658957)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"embs\"][4] @ a[\"embs\"][5], a[\"embs\"][4] @ a[\"embs\"][6], a[\"embs\"][4] @ a[\"embs\"][\n",
    "    9\n",
    "], a[\"embs\"][4] @ a[\"embs\"][10], a[\"embs\"][4] @ a[\"embs\"][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51033, 512), (51033, 1))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds_embs[\"embs\"].shape, full_ds_embs[\"unc\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_whale_dataset(\n",
    "    train_dataset, test_unique_ids, test_count_ids, full_ds_embs, \"whale\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_dataset.x_paths).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dir = identification_ds_path / \"embeddings\"\n",
    "emb_dir.mkdir(exist_ok=True)\n",
    "np.savez(emb_dir / \"b6_embs_whale.npz\", **a, unc=np.ones((a[\"embs\"].shape[0], 1)) * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((a[\"embs\"].shape[0], 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
